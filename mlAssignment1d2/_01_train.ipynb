{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Read-raw-training-data\" data-toc-modified-id=\"Read-raw-training-data-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Read raw training data</a></span></li><li><span><a href=\"#Attempt-to-use-Pipeline-a-la-tutorial\" data-toc-modified-id=\"Attempt-to-use-Pipeline-a-la-tutorial-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Attempt to use Pipeline a la <a href=\"http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#extracting-features-from-text-files\" target=\"_blank\">tutorial</a></a></span></li><li><span><a href=\"#Creating-My-Own-Custom-Pipeline-(I-HOPE)\" data-toc-modified-id=\"Creating-My-Own-Custom-Pipeline-(I-HOPE)-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Creating My Own Custom Pipeline (I HOPE)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quantitative-Features-Extractor\" data-toc-modified-id=\"Quantitative-Features-Extractor-0.3.1\"><span class=\"toc-item-num\">0.3.1&nbsp;&nbsp;</span>Quantitative Features Extractor</a></span></li><li><span><a href=\"#Select-Text-Field\" data-toc-modified-id=\"Select-Text-Field-0.3.2\"><span class=\"toc-item-num\">0.3.2&nbsp;&nbsp;</span>Select Text Field</a></span></li><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-0.3.3\"><span class=\"toc-item-num\">0.3.3&nbsp;&nbsp;</span>Pipeline</a></span></li></ul></li><li><span><a href=\"#Attempt-to-Use-FeaturePrep-Module-to-prepare-features\" data-toc-modified-id=\"Attempt-to-Use-FeaturePrep-Module-to-prepare-features-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Attempt to Use FeaturePrep Module to prepare features</a></span></li><li><span><a href=\"#Feature-Creation1:-ProductID-Aggregates\" data-toc-modified-id=\"Feature-Creation1:-ProductID-Aggregates-0.5\"><span class=\"toc-item-num\">0.5&nbsp;&nbsp;</span>Feature Creation1: ProductID Aggregates</a></span></li><li><span><a href=\"#Feature-Creation2-:-natural-language-on-the-subject-line\" data-toc-modified-id=\"Feature-Creation2-:-natural-language-on-the-subject-line-0.6\"><span class=\"toc-item-num\">0.6&nbsp;&nbsp;</span>Feature Creation2 : natural language on the subject line</a></span></li><li><span><a href=\"#Feature-extraction-on-natural-language-data\" data-toc-modified-id=\"Feature-extraction-on-natural-language-data-0.7\"><span class=\"toc-item-num\">0.7&nbsp;&nbsp;</span>Feature extraction on natural language data</a></span></li><li><span><a href=\"#Create-additional-quantitative-features\" data-toc-modified-id=\"Create-additional-quantitative-features-0.8\"><span class=\"toc-item-num\">0.8&nbsp;&nbsp;</span>Create additional quantitative features</a></span></li><li><span><a href=\"#Combine-all-quantitative-features-into-a-single-sparse-matrix\" data-toc-modified-id=\"Combine-all-quantitative-features-into-a-single-sparse-matrix-0.9\"><span class=\"toc-item-num\">0.9&nbsp;&nbsp;</span>Combine all quantitative features into a single sparse matrix</a></span></li><li><span><a href=\"#Create-X,-scaled-matrix-of-features\" data-toc-modified-id=\"Create-X,-scaled-matrix-of-features-0.10\"><span class=\"toc-item-num\">0.10&nbsp;&nbsp;</span>Create <code>X</code>, scaled matrix of features</a></span></li></ul></li><li><span><a href=\"#create-y,-vector-of-Labels\" data-toc-modified-id=\"create-y,-vector-of-Labels-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>create <code>y</code>, vector of Labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#fit-models\" data-toc-modified-id=\"fit-models-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>fit models</a></span></li><li><span><a href=\"#ROC-plot-to-compare-performance-of-various-models-and-fits\" data-toc-modified-id=\"ROC-plot-to-compare-performance-of-various-models-and-fits-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>ROC plot to compare performance of various models and fits</a></span></li></ul></li><li><span><a href=\"#Looking-into-model-predictions\" data-toc-modified-id=\"Looking-into-model-predictions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Looking into model predictions</a></span><ul class=\"toc-item\"><li><span><a href=\"#First-checking-to-make-sure-that-the-records-haven't-changed-order-through-our-feature-prep\" data-toc-modified-id=\"First-checking-to-make-sure-that-the-records-haven't-changed-order-through-our-feature-prep-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>First checking to make sure that the records haven't changed order through our feature prep</a></span></li></ul></li><li><span><a href=\"#Add-predictions-to-original-data\" data-toc-modified-id=\"Add-predictions-to-original-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Add predictions to original data</a></span></li><li><span><a href=\"#Look-at-cases-where-at-least-1-indicator-said-true\" data-toc-modified-id=\"Look-at-cases-where-at-least-1-indicator-said-true-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Look at cases where at least 1 indicator said true</a></span></li><li><span><a href=\"#Helpfullness-Matrix\" data-toc-modified-id=\"Helpfullness-Matrix-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Helpfullness Matrix</a></span></li><li><span><a href=\"#Explore-NBS-Performance-via-Particular-Instances\" data-toc-modified-id=\"Explore-NBS-Performance-via-Particular-Instances-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Explore NBS Performance via Particular Instances</a></span><ul class=\"toc-item\"><li><span><a href=\"#NBS-False-Negatives----Helpful-reviews-we-missed\" data-toc-modified-id=\"NBS-False-Negatives----Helpful-reviews-we-missed-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>NBS False Negatives -- Helpful reviews we missed</a></span></li><li><span><a href=\"#NBS-False-Positives----mistakely-tagged-reviews-as-helpful\" data-toc-modified-id=\"NBS-False-Positives----mistakely-tagged-reviews-as-helpful-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>NBS False Positives -- mistakely tagged reviews as helpful</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 14)\n",
      "['Unnamed: 0', 'Unnamed: 0.1', 'Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text', 'helpScore', 'helpful']\n"
     ]
    }
   ],
   "source": [
    "amazon = pd.read_csv('../../../data/amazon_data/raw_data_train.csv')\n",
    "print(amazon.shape)\n",
    "\n",
    "#noticed here that we gained a column -- looking at what it is\n",
    "print(list(amazon)) # got another unnamed column (some sort of index?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0      325101        150237  150238  B001STX13U  A25KKXUQQ0OLWB   \n",
      "1      376619        213859  213860  B0000DCXCM  A1NCFPKB690L3G   \n",
      "2      244837        385642  385643  B007FRCNCE  A2EG7IWLQIXQMX   \n",
      "3      270468        102738  102739  B002L96X68   AAUICTIUBVU7R   \n",
      "4       42280        313513  313514  B000FNJ69S  A3S62P7QTO4P8V   \n",
      "\n",
      "                          ProfileName  HelpfulnessNumerator  \\\n",
      "0  Lynn Ellingwood \"The ESOL Teacher\"                    10   \n",
      "1                       Anna R. Brown                     1   \n",
      "2   Zachariah Green \"Zachariah Green\"                     2   \n",
      "3               Roy Berger \"Everyman\"                     0   \n",
      "4            Chad Susott \"Sparty DDS\"                     3   \n",
      "\n",
      "   HelpfulnessDenominator  Score        Time                  Summary  \\\n",
      "0                      10      5  1282348800  My Cats' Favorite Food!   \n",
      "1                       2      1  1267920000                Too salty   \n",
      "2                       2      5  1300320000               Great Tea!   \n",
      "3                       0      5  1341446400   YUM, YUM, YUM TERRIFIC   \n",
      "4                       4      5  1283040000         Great with Sushi   \n",
      "\n",
      "                                                Text  helpScore  helpful  \n",
      "0  When this food came out, my cats went crazy th...       1.00     True  \n",
      "1  The almonds in this mix were great - crunchy w...       0.50    False  \n",
      "2  This is one of my favorites... Most relaxing t...       1.00    False  \n",
      "3  Great flavor and plenty of it! It's like eatin...        NaN    False  \n",
      "4  I'm not a wasabi connoisseur by any means but ...       0.75    False  \n",
      "(364000, 14)\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to use Pipeline a la [tutorial](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#extracting-features-from-text-files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364000, 99182)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Start by Tokenizing the Text - not using the Hashing trick \n",
    "#because don't know how to put that in the pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(amazon.Text)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364000, 99182)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add in tf-idf transformations \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model\n",
    "text_clf.fit(amazon.Text, amazon.helpful) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#See how model performed on the training data\n",
    "predict = text_clf.predict(amazon.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92674725274725278"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(predict == amazon.helpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': [2, 1, 0, 1e-2],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "gs_clf = gs_clf.fit(amazon.Text[:1000], \n",
    "                    amazon.helpful[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM GridSearch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf2 = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf2 = gs_clf2.fit(amazon.Text[:1000], amazon.helpful[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926\n",
      "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf2.best_score_)\n",
    "print(gs_clf2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating My Own Custom Pipeline (I HOPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative Features Extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class CalculateQuantativeFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Takes in dataframe, extracts road name column, outputs average word length\"\"\"\n",
    "    from scipy.sparse import csr_matrix\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compute_product_aggregates(self, df):\n",
    "        '''Computes aggregates for each 'ProductId' Returns\n",
    "        data frame with additional 2 columns for 'minTimePerProduct' \n",
    "        and 'numReviewsPerProduct'''\n",
    "        #define aggregations on 'ProductId' group\n",
    "        aggregations = {'Time': 'min','Id': \"count\"}\n",
    "        \n",
    "        #create groupBy object on 'ProductId' and preform aggregations\n",
    "        #'as_index = False' so we have the 'ProductId' column to join on later\n",
    "        productGrouped = df.groupby(['ProductId'], as_index= False).agg(aggregations)\n",
    "        \n",
    "        # rename columns\n",
    "        productGrouped = productGrouped.rename(columns={\"Time\": \"minTimePerProduct\",'Id': 'numReviewsPerProduct'})\n",
    "        \n",
    "        # add merged values to original data\n",
    "        merged = pd.merge(df, productGrouped, how = 'left', on = ['ProductId'])\n",
    "        \n",
    "        merged['timeDiffFromFirstReview'] = merged[\"Time\"]-merged[\"minTimePerProduct\"]\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def transform(self, df):\n",
    "        '''The workhorse of this feature extractor'''\n",
    "        # calculates raw data merged with product aggregates\n",
    "        quantFeatures = self.compute_product_aggregates(df)\n",
    "        \n",
    "        #create column for str length of text\n",
    "        quantFeatures['reviewLen'] = quantFeatures['Text'].str.len()\n",
    "        \n",
    "        X_quant_features = quantFeatures[[\"Score\", \n",
    "                                          \"reviewLen\", \n",
    "                                          \"minTimePerProduct\", \n",
    "                                          \"numReviewsPerProduct\", \n",
    "                                          \"timeDiffFromFirstReview\"]]\n",
    "        \n",
    "        #convert to sparce matric so can be combined with other features\n",
    "        X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "        return X_quant_features_csr\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        '''Returns `self` unless something different happens in train and test'''\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantTransform = CalculateQuantativeFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<364000x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1757969 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantTransform.transform(amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Text Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SelectCol(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, col='Text'):\n",
    "        self.col = col\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.col == 'Summary':\n",
    "            return X[self.col].values.astype('str')\n",
    "        else:\n",
    "            return X[self.col]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"My Cats' Favorite Food!\", 'Too salty', 'Great Tea!', ...,\n",
       "       'The Best for Baking!', 'Magical', 'Great product, bad price'],\n",
       "      dtype='<U128')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = SelectCol(col='Summary')\n",
    "select.transform(amazon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ref1](https://michelleful.github.io/code-blog/2015/06/20/pipelines/)\n",
    "[Ref2](http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "from pipelineHelpers import CalculateQuantativeFeatures, SelectCol\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('feats', FeatureUnion([ \n",
    "        ('text', Pipeline([\n",
    "            ## Select Text Col and pass it to text analysis\n",
    "            ('select', SelectCol(col='Text')),\n",
    "            ## Hash Vect\n",
    "            ('vect', HashingVectorizer(n_features=2 ** 17, non_negative=True)),\n",
    "            ## TFIDF\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "        ])),\n",
    "        ('summary', Pipeline([\n",
    "            ## Select Summary Col and pass it to text analysis\n",
    "            ('selectSum', SelectCol(col='Summary')),\n",
    "            ## Hash Vect\n",
    "            ('vectSum', HashingVectorizer(n_features=2 ** 17, non_negative=True)),\n",
    "            ## TFIDF\n",
    "            ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "        ])),\n",
    "        ('quant', CalculateQuantativeFeatures())        \n",
    "    ])),\n",
    "    ('scale', StandardScaler(with_mean=False)),\n",
    "    ('clf', MultinomialNB())  # classifier\n",
    "#     ('clf', SGDClassifier(alpha=1e-3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feats', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(memory=None,\n",
       "     steps=[('select', SelectCol(col='Text')), ('vect', HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "         decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "         encodi...th_mean=False, with_std=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(amazon, amazon.helpful) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "predict = text_clf.predict(amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87025824175824174"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict == amazon.helpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(text_clf, 'pipeline.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'clf__alpha': [1e-2, 1e-3, 0],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10b67ced0, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10b67ced0, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 26, 0, 57, 50, 205228, tzinfo=tzutc()), 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'session': '8A9910C5374B41E28FAE9D55F09EB3A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'8A9910C5374B41E28FAE9D55F09EB3A1']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 26, 0, 57, 50, 205228, tzinfo=tzutc()), 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'session': '8A9910C5374B41E28FAE9D55F09EB3A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'8A9910C5374B41E28FAE9D55F09EB3A1'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 26, 0, 57, 50, 205228, tzinfo=tzutc()), 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'session': '8A9910C5374B41E28FAE9D55F09EB3A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-147-079d632c9e90>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1515a1eeb8, execution..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x152ea72b70, file \"<ipython-input-147-079d632c9e90>\", line 2>\n        result = <ExecutionResult object at 1515a1eeb8, execution..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x152ea72b70, file \"<ipython-input-147-079d632c9e90>\", line 2>, result=<ExecutionResult object at 1515a1eeb8, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x152ea72b70, file \"<ipython-input-147-079d632c9e90>\", line 2>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CalculateQuantativeFeatures': <class '__main__.CalculateQuantativeFeatures'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', \"import numpy as np\\nimport pandas as pd\\nimport ma...t joblib\\nget_ipython().magic('matplotlib inline')\", \"amazon = pd.read_csv('../../../data/amazon_data/... got another unnamed column (some sort of index?)\", '# print(amazon.head())\\nprint(amazon.shape)', \"amazon = pd.read_csv('../../../data/amazon_data/... got another unnamed column (some sort of index?)\", '# print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t_vect.fit_transform(amazon)\\nX_train_counts.shape', '# print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t_vect.fit_transform(amazon)\\nX_train_counts.shape', 'print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t.fit_transform(amazon.Text)\\nX_train_counts.shape', '#Add in tf-idf transformations \\nfrom sklearn.fea...former.transform(X_train_counts)\\nX_train_tf.shape', \"from sklearn.pipeline import Pipeline\\ntext_clf =...,\\n                    ('clf', MultinomialNB()),])\", \"from sklearn.pipeline import Pipeline\\nfrom sklea...),\\n                    ('clf', MultinomialNB())])\", '#Fit Model\\ntext_clf.fit(twenty_train.data, twenty_train.target)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.Helpful)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.helpful)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.helpful) ', '#See how model performed on the training data\\ntext_clf.predict(amazon.Text)', '#See how model performed on the training data\\npredict = text_clf.predict(amazon.Text)', ...], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {6: (14, 13), 8: (14, 13), 10: (364000, 99182), 11: (364000, 99182), 17: Pipeline(memory=None,\n     steps=[('vect', Count...B(alpha=1.0, class_prior=None, fit_prior=True))]), 18: array([False, False, False, ..., False, False, False], dtype=bool), 23: 0.92674725274725278, 30: GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), 31: 0.92600000000000005, 32: {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}, ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CalculateQuantativeFeatures': <class '__main__.CalculateQuantativeFeatures'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', \"import numpy as np\\nimport pandas as pd\\nimport ma...t joblib\\nget_ipython().magic('matplotlib inline')\", \"amazon = pd.read_csv('../../../data/amazon_data/... got another unnamed column (some sort of index?)\", '# print(amazon.head())\\nprint(amazon.shape)', \"amazon = pd.read_csv('../../../data/amazon_data/... got another unnamed column (some sort of index?)\", '# print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t_vect.fit_transform(amazon)\\nX_train_counts.shape', '# print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t_vect.fit_transform(amazon)\\nX_train_counts.shape', 'print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t.fit_transform(amazon.Text)\\nX_train_counts.shape', '#Add in tf-idf transformations \\nfrom sklearn.fea...former.transform(X_train_counts)\\nX_train_tf.shape', \"from sklearn.pipeline import Pipeline\\ntext_clf =...,\\n                    ('clf', MultinomialNB()),])\", \"from sklearn.pipeline import Pipeline\\nfrom sklea...),\\n                    ('clf', MultinomialNB())])\", '#Fit Model\\ntext_clf.fit(twenty_train.data, twenty_train.target)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.Helpful)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.helpful)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.helpful) ', '#See how model performed on the training data\\ntext_clf.predict(amazon.Text)', '#See how model performed on the training data\\npredict = text_clf.predict(amazon.Text)', ...], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {6: (14, 13), 8: (14, 13), 10: (364000, 99182), 11: (364000, 99182), 17: Pipeline(memory=None,\n     steps=[('vect', Count...B(alpha=1.0, class_prior=None, fit_prior=True))]), 18: array([False, False, False, ..., False, False, False], dtype=bool), 23: 0.92674725274725278, 30: GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), 31: 0.92600000000000005, 32: {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}, ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/aucherserr/Desktop/MachineLearning/myGit/ml/mlAssignment1d2/<ipython-input-147-079d632c9e90> in <module>()\n      1 gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n      2 gs_clf = gs_clf.fit(amazon[:1000], \n----> 3                     amazon.helpful[:1000])\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), X=     Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], y=0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns]\n        y = 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Mar 25 20:57:51 2018\nPID: 53599                              Python 3.6.3: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]),      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, {'score': <function _passthrough_scorer>}, array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), 0, {'clf__alpha': 0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]),      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, {'score': <function _passthrough_scorer>}, array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), 0, {'clf__alpha': 0})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), X=     Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], y=0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, scorer={'score': <function _passthrough_scorer>}, train=array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), verbose=0, parameters={'clf__alpha': 0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'clf__alpha': 0}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'clf__alpha': 0})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'clf__alpha': 0}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'clf__alpha': 0})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'clf__alpha': 0}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), **params={'clf__alpha': 0})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'clf': SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__alpha': 0.001, 'clf__average': False, 'clf__class_weight': None, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', ...}\n        key.set_params = undefined\n        sub_params = {'alpha': 0}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'alpha': 0})\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n     77         super(BaseSGD, self).set_params(*args, **kwargs)\n---> 78         self._validate_params(set_max_iter=False)\n        self._validate_params = <bound method BaseSGD._validate_params of SGDCla...fle=True, tol=None, verbose=0, warm_start=False)>\n     79         return self\n     80 \n     81     @abstractmethod\n     82     def fit(self, X, y):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py in _validate_params(self=SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), set_max_iter=False)\n     94             raise ValueError(\"alpha must be >= 0\")\n     95         if self.learning_rate in (\"constant\", \"invscaling\"):\n     96             if self.eta0 <= 0.0:\n     97                 raise ValueError(\"eta0 must be > 0\")\n     98         if self.learning_rate == \"optimal\" and self.alpha == 0:\n---> 99             raise ValueError(\"alpha must be > 0 since \"\n    100                              \"learning_rate is 'optimal'. alpha is used \"\n    101                              \"to compute the optimal learning rate.\")\n    102 \n    103         # raises ValueError if not registered\n\nValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 282, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\", line 78, in set_params\n    self._validate_params(set_max_iter=False)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\", line 99, in _validate_params\n    raise ValueError(\"alpha must be > 0 since \"\nValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Mar 25 20:57:51 2018\nPID: 53599                              Python 3.6.3: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]),      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, {'score': <function _passthrough_scorer>}, array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), 0, {'clf__alpha': 0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]),      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, {'score': <function _passthrough_scorer>}, array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), 0, {'clf__alpha': 0})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), X=     Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], y=0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, scorer={'score': <function _passthrough_scorer>}, train=array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), verbose=0, parameters={'clf__alpha': 0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'clf__alpha': 0}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'clf__alpha': 0})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'clf__alpha': 0}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'clf__alpha': 0})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'clf__alpha': 0}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), **params={'clf__alpha': 0})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'clf': SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__alpha': 0.001, 'clf__average': False, 'clf__class_weight': None, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', ...}\n        key.set_params = undefined\n        sub_params = {'alpha': 0}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'alpha': 0})\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n     77         super(BaseSGD, self).set_params(*args, **kwargs)\n---> 78         self._validate_params(set_max_iter=False)\n        self._validate_params = <bound method BaseSGD._validate_params of SGDCla...fle=True, tol=None, verbose=0, warm_start=False)>\n     79         return self\n     80 \n     81     @abstractmethod\n     82     def fit(self, X, y):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py in _validate_params(self=SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), set_max_iter=False)\n     94             raise ValueError(\"alpha must be >= 0\")\n     95         if self.learning_rate in (\"constant\", \"invscaling\"):\n     96             if self.eta0 <= 0.0:\n     97                 raise ValueError(\"eta0 must be > 0\")\n     98         if self.learning_rate == \"optimal\" and self.alpha == 0:\n---> 99             raise ValueError(\"alpha must be > 0 since \"\n    100                              \"learning_rate is 'optimal'. alpha is used \"\n    101                              \"to compute the optimal learning rate.\")\n    102 \n    103         # raises ValueError if not registered\n\nValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Mar 25 20:57:51 2018\nPID: 53599                              Python 3.6.3: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]),      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, {'score': <function _passthrough_scorer>}, array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), 0, {'clf__alpha': 0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]),      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, {'score': <function _passthrough_scorer>}, array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), 0, {'clf__alpha': 0})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), X=     Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], y=0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, scorer={'score': <function _passthrough_scorer>}, train=array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), verbose=0, parameters={'clf__alpha': 0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'clf__alpha': 0}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'clf__alpha': 0})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'clf__alpha': 0}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'clf__alpha': 0})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'clf__alpha': 0}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), **params={'clf__alpha': 0})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'clf': SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__alpha': 0.001, 'clf__average': False, 'clf__class_weight': None, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', ...}\n        key.set_params = undefined\n        sub_params = {'alpha': 0}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'alpha': 0})\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n     77         super(BaseSGD, self).set_params(*args, **kwargs)\n---> 78         self._validate_params(set_max_iter=False)\n        self._validate_params = <bound method BaseSGD._validate_params of SGDCla...fle=True, tol=None, verbose=0, warm_start=False)>\n     79         return self\n     80 \n     81     @abstractmethod\n     82     def fit(self, X, y):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py in _validate_params(self=SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), set_max_iter=False)\n     94             raise ValueError(\"alpha must be >= 0\")\n     95         if self.learning_rate in (\"constant\", \"invscaling\"):\n     96             if self.eta0 <= 0.0:\n     97                 raise ValueError(\"eta0 must be > 0\")\n     98         if self.learning_rate == \"optimal\" and self.alpha == 0:\n---> 99             raise ValueError(\"alpha must be > 0 since \"\n    100                              \"learning_rate is 'optimal'. alpha is used \"\n    101                              \"to compute the optimal learning rate.\")\n    102 \n    103         # raises ValueError if not registered\n\nValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-079d632c9e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m gs_clf = gs_clf.fit(amazon[:1000], \n\u001b[0;32m----> 3\u001b[0;31m                     amazon.helpful[:1000])\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10b67ced0, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10b67ced0, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 26, 0, 57, 50, 205228, tzinfo=tzutc()), 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'session': '8A9910C5374B41E28FAE9D55F09EB3A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'8A9910C5374B41E28FAE9D55F09EB3A1']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 26, 0, 57, 50, 205228, tzinfo=tzutc()), 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'session': '8A9910C5374B41E28FAE9D55F09EB3A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'8A9910C5374B41E28FAE9D55F09EB3A1'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 26, 0, 57, 50, 205228, tzinfo=tzutc()), 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'session': '8A9910C5374B41E28FAE9D55F09EB3A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'ACD3BCE4E1E6455BA90CA60371317D3D', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='gs_clf = GridSearchCV(text_clf, parameters, n_jo...000], \\n                    amazon.helpful[:1000])', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-147-079d632c9e90>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1515a1eeb8, execution..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x152ea72b70, file \"<ipython-input-147-079d632c9e90>\", line 2>\n        result = <ExecutionResult object at 1515a1eeb8, execution..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x152ea72b70, file \"<ipython-input-147-079d632c9e90>\", line 2>, result=<ExecutionResult object at 1515a1eeb8, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x152ea72b70, file \"<ipython-input-147-079d632c9e90>\", line 2>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CalculateQuantativeFeatures': <class '__main__.CalculateQuantativeFeatures'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', \"import numpy as np\\nimport pandas as pd\\nimport ma...t joblib\\nget_ipython().magic('matplotlib inline')\", \"amazon = pd.read_csv('../../../data/amazon_data/... got another unnamed column (some sort of index?)\", '# print(amazon.head())\\nprint(amazon.shape)', \"amazon = pd.read_csv('../../../data/amazon_data/... got another unnamed column (some sort of index?)\", '# print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t_vect.fit_transform(amazon)\\nX_train_counts.shape', '# print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t_vect.fit_transform(amazon)\\nX_train_counts.shape', 'print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t.fit_transform(amazon.Text)\\nX_train_counts.shape', '#Add in tf-idf transformations \\nfrom sklearn.fea...former.transform(X_train_counts)\\nX_train_tf.shape', \"from sklearn.pipeline import Pipeline\\ntext_clf =...,\\n                    ('clf', MultinomialNB()),])\", \"from sklearn.pipeline import Pipeline\\nfrom sklea...),\\n                    ('clf', MultinomialNB())])\", '#Fit Model\\ntext_clf.fit(twenty_train.data, twenty_train.target)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.Helpful)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.helpful)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.helpful) ', '#See how model performed on the training data\\ntext_clf.predict(amazon.Text)', '#See how model performed on the training data\\npredict = text_clf.predict(amazon.Text)', ...], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {6: (14, 13), 8: (14, 13), 10: (364000, 99182), 11: (364000, 99182), 17: Pipeline(memory=None,\n     steps=[('vect', Count...B(alpha=1.0, class_prior=None, fit_prior=True))]), 18: array([False, False, False, ..., False, False, False], dtype=bool), 23: 0.92674725274725278, 30: GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), 31: 0.92600000000000005, 32: {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}, ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CalculateQuantativeFeatures': <class '__main__.CalculateQuantativeFeatures'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', \"import numpy as np\\nimport pandas as pd\\nimport ma...t joblib\\nget_ipython().magic('matplotlib inline')\", \"amazon = pd.read_csv('../../../data/amazon_data/... got another unnamed column (some sort of index?)\", '# print(amazon.head())\\nprint(amazon.shape)', \"amazon = pd.read_csv('../../../data/amazon_data/... got another unnamed column (some sort of index?)\", '# print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t_vect.fit_transform(amazon)\\nX_train_counts.shape', '# print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t_vect.fit_transform(amazon)\\nX_train_counts.shape', 'print(amazon.head())\\nprint(amazon.shape)', 'from sklearn.feature_extraction.text import Coun...t.fit_transform(amazon.Text)\\nX_train_counts.shape', '#Add in tf-idf transformations \\nfrom sklearn.fea...former.transform(X_train_counts)\\nX_train_tf.shape', \"from sklearn.pipeline import Pipeline\\ntext_clf =...,\\n                    ('clf', MultinomialNB()),])\", \"from sklearn.pipeline import Pipeline\\nfrom sklea...),\\n                    ('clf', MultinomialNB())])\", '#Fit Model\\ntext_clf.fit(twenty_train.data, twenty_train.target)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.Helpful)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.helpful)  \\nPipeline(...)', '#Fit Model\\ntext_clf.fit(amazon.Text, amazon.helpful) ', '#See how model performed on the training data\\ntext_clf.predict(amazon.Text)', '#See how model performed on the training data\\npredict = text_clf.predict(amazon.Text)', ...], 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {6: (14, 13), 8: (14, 13), 10: (364000, 99182), 11: (364000, 99182), 17: Pipeline(memory=None,\n     steps=[('vect', Count...B(alpha=1.0, class_prior=None, fit_prior=True))]), 18: array([False, False, False, ..., False, False, False], dtype=bool), 23: 0.92674725274725278, 30: GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), 31: 0.92600000000000005, 32: {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}, ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/aucherserr/Desktop/MachineLearning/myGit/ml/mlAssignment1d2/<ipython-input-147-079d632c9e90> in <module>()\n      1 gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n      2 gs_clf = gs_clf.fit(amazon[:1000], \n----> 3                     amazon.helpful[:1000])\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), X=     Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], y=0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns]\n        y = 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Mar 25 20:57:51 2018\nPID: 53599                              Python 3.6.3: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]),      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, {'score': <function _passthrough_scorer>}, array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), 0, {'clf__alpha': 0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]),      Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], 0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, {'score': <function _passthrough_scorer>}, array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), 0, {'clf__alpha': 0})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), X=     Unnamed: 0  Unnamed: 0.1      Id   ProductI....        NaN    False  \n\n[1000 rows x 14 columns], y=0       True\n1      False\n2      False\n3      Fa...   False\nName: helpful, Length: 1000, dtype: bool, scorer={'score': <function _passthrough_scorer>}, train=array([329, 330, 331, 332, 333, 334, 335, 337, 3..., 992, 993, 994, 995, 996,\n       997, 998, 999]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    325, 326, 327, 328, 336, 362, 376, 377, 380]), verbose=0, parameters={'clf__alpha': 0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'clf__alpha': 0}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'clf__alpha': 0})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'clf__alpha': 0}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'clf__alpha': 0})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'clf__alpha': 0}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('feats', Feat...e=True, tol=None, verbose=0, warm_start=False))]), **params={'clf__alpha': 0})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'clf': SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__alpha': 0.001, 'clf__average': False, 'clf__class_weight': None, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', ...}\n        key.set_params = undefined\n        sub_params = {'alpha': 0}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'alpha': 0})\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n     77         super(BaseSGD, self).set_params(*args, **kwargs)\n---> 78         self._validate_params(set_max_iter=False)\n        self._validate_params = <bound method BaseSGD._validate_params of SGDCla...fle=True, tol=None, verbose=0, warm_start=False)>\n     79         return self\n     80 \n     81     @abstractmethod\n     82     def fit(self, X, y):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py in _validate_params(self=SGDClassifier(alpha=0, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), set_max_iter=False)\n     94             raise ValueError(\"alpha must be >= 0\")\n     95         if self.learning_rate in (\"constant\", \"invscaling\"):\n     96             if self.eta0 <= 0.0:\n     97                 raise ValueError(\"eta0 must be > 0\")\n     98         if self.learning_rate == \"optimal\" and self.alpha == 0:\n---> 99             raise ValueError(\"alpha must be > 0 since \"\n    100                              \"learning_rate is 'optimal'. alpha is used \"\n    101                              \"to compute the optimal learning rate.\")\n    102 \n    103         # raises ValueError if not registered\n\nValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(amazon[:1000], \n",
    "                    amazon.helpful[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-988cca0cfa95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to Use FeaturePrep Module to prepare features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try out new module\n",
    "from featuresPreparation import AmazonReviewFeaturePrep\n",
    "# moduleDataTest = pd.read_csv('../../../data/amazon_data/raw_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurePrepTest = amazon\n",
    "featurePrepTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurePreparer = AmazonReviewFeaturePrep(featurePrepTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 14)\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(featurePreparer.rawData.shape)\n",
    "print(featurePreparer.X)\n",
    "print(featurePreparer.summary_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to compute features (out of 14)\n",
      "3. starting tfidf\n",
      "1. starting Hash Vectorizor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. hv.pkl saved\n",
      "4. transformer.pkl saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. starting Summary Text Stats\n",
      "6. summary_hv.pkl saved\n",
      "7. summary_transformer.pkl saved\n",
      "8. starting quant features\n",
      "9. starting product aggregates\n",
      "10. finished product aggregates\n",
      "11. finished quant features\n",
      "12. starting matrix scaling\n",
      "13. sc.pkl saved\n",
      "14. finished computing all features\n"
     ]
    }
   ],
   "source": [
    "featurePreparer.compute_all_features_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = featurePreparer.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364000, 262149)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation1: ProductID Aggregates\n",
    "Minimum 'Time' and Number of Reviews per 'ProductId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductId\n",
      "0006641040     939340800\n",
      "141278509X    1332547200\n",
      "2734888454    1192060800\n",
      "7310172001    1104796800\n",
      "7310172101    1104796800\n",
      "Name: Time, dtype: int64\n",
      "ProductId\n",
      "0006641040     28\n",
      "141278509X      1\n",
      "2734888454      1\n",
      "7310172001    107\n",
      "7310172101    118\n",
      "Name: Id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ATTEMPT 1: get product groupings\n",
    "\n",
    "# #First need to find the first review date for each product id\n",
    "# productGrouped = amazon.groupby(['ProductId'])\n",
    "\n",
    "\n",
    "# ## first time per productid\n",
    "# minTimePerProduct = productGrouped['Time'].min()\n",
    "# print(minTimePerProduct.head())\n",
    "\n",
    "# ## number of reviews per product id\n",
    "# numReviewsPerProduct = productGrouped['Id'].count()\n",
    "# print(numReviewsPerProduct.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ATTEMPT 2: at groupby aggregations -- MOVED TO MODULE\n",
    "# aggregations = {\n",
    "#     'Time': 'min',\n",
    "#     'Id': \"count\"\n",
    "# }\n",
    "\n",
    "# # as_index = False to ensure that we have the 'ProductId' column to join on later\n",
    "# productGrouped = amazon.groupby(['ProductId'], as_index= False).agg(aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # rename columns\n",
    "# productGrouped = productGrouped.rename(columns={\"Time\": \"minTimePerProduct\",\n",
    "#                                                 'Id': 'numReviewsPerProduct'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # join aggregates back to original data\n",
    "\n",
    "# # check to make sure didn't lose any data in join\n",
    "# pd.merge(amazon, productGrouped, how = 'left', on = ['ProductId']).shape\n",
    "\n",
    "# # add merged values to original data\n",
    "# amazon = pd.merge(amazon, productGrouped, how = 'left', on = ['ProductId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173465</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1281139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1282348800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311307</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1285372800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316493</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1306972800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347088</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1313712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125018</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1320364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45067</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1320364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182736</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1322265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43133</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1323993600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239698</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1324425600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189628</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1327017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207186</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1328140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139691</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1329436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204128</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1330560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40346</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1333152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211821</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1334534400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307088</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1335484800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89232</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1335571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275789</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1335830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220805</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1342310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264803</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1347062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198342</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1347321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87693</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1349395200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177709</th>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>1350950400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ProductId        Time\n",
       "173465  B001STX13U  1281139200\n",
       "0       B001STX13U  1282348800\n",
       "311307  B001STX13U  1285372800\n",
       "316493  B001STX13U  1306972800\n",
       "347088  B001STX13U  1313712000\n",
       "125018  B001STX13U  1320364800\n",
       "45067   B001STX13U  1320364800\n",
       "182736  B001STX13U  1322265600\n",
       "43133   B001STX13U  1323993600\n",
       "239698  B001STX13U  1324425600\n",
       "189628  B001STX13U  1327017600\n",
       "207186  B001STX13U  1328140800\n",
       "139691  B001STX13U  1329436800\n",
       "204128  B001STX13U  1330560000\n",
       "40346   B001STX13U  1333152000\n",
       "211821  B001STX13U  1334534400\n",
       "307088  B001STX13U  1335484800\n",
       "89232   B001STX13U  1335571200\n",
       "275789  B001STX13U  1335830400\n",
       "220805  B001STX13U  1342310400\n",
       "264803  B001STX13U  1347062400\n",
       "198342  B001STX13U  1347321600\n",
       "87693   B001STX13U  1349395200\n",
       "177709  B001STX13U  1350950400"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # check specitic product to make sure the date makes sense\n",
    "# amazon[amazon['ProductId'] == 'B001STX13U'][['ProductId','Time']].sort_values('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation2 : natural language on the subject line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"My Cats' Favorite Food!\", 'Too salty', 'Great Tea!', ...,\n",
       "       'The Best for Baking!', 'Magical', 'Great product, bad price'],\n",
       "      dtype='<U128')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.Summary.values.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 131072)\n"
     ]
    }
   ],
   "source": [
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "summary_hv = hv.fit_transform(amazon.Summary.values.astype('str'))\n",
    "print(summary_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70710678,  0.70710678,  0.70710678, ...,  0.70710678,\n",
       "        0.70710678,  1.        ])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_hv.data[summary_hv.data != 0.5]\n",
    "# print(X_hv.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 131072)\n",
      "[ 0.51238549  0.48096614  0.401309   ...,  0.61929034  0.46916704\n",
      "  0.53337948]\n"
     ]
    }
   ],
   "source": [
    "summary_tfidf = transformer.fit_transform(summary_hv)\n",
    "print(summary_tfidf.shape)\n",
    "print(summary_tfidf.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 131072)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "X_hv = hv.fit_transform(amazon.Text)\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hv.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to be able to use this model fit on other data (the test set)\n",
    "# So let's save a copy of this instance of HashingVectorizer to be able to transform other data with this fit\n",
    "# http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "joblib.dump(hv, 'hv.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer.pkl']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_hv)\n",
    "\n",
    "joblib.dump(transformer, 'transformer.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  reviewLen\n",
      "0  5      333      \n",
      "1  1      114      \n",
      "2  5      145      \n",
      "3  5      247      \n",
      "4  5      266      \n",
      "5  1      346      \n",
      "6  5      1256     \n",
      "7  5      247      \n",
      "8  5      131      \n",
      "9  5      143      \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "\n",
    "X_quant_features = amazon[[\"Score\", \"reviewLen\"]]\n",
    "print(X_quant_features.head(10))\n",
    "print(type(X_quant_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 262146)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "# converting quant features to sparse matrix\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "# stacking them together to concatinate them\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr, summary_tfidf])\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape) # added two columns to previous shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `X`, scaled matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 131074)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sc.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "# X = sc.fit_transform(X_matrix) # get all features on the same scale\n",
    "# print(X.shape)\n",
    "\n",
    "joblib.dump(sc, 'sc.pkl') # pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Unnamed: 0.1',\n",
       " 'Id',\n",
       " 'ProductId',\n",
       " 'UserId',\n",
       " 'ProfileName',\n",
       " 'HelpfulnessNumerator',\n",
       " 'HelpfulnessDenominator',\n",
       " 'Score',\n",
       " 'Time',\n",
       " 'Summary',\n",
       " 'Text',\n",
       " 'helpScore',\n",
       " 'helpful']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34189\n",
      "54788\n",
      "26527\n"
     ]
    }
   ],
   "source": [
    "# create alternate helpful score\n",
    "amazon['newHelpful'] =\\\n",
    "((amazon.HelpfulnessDenominator > 3) & (amazon.helpScore >= 0.8) |)\n",
    "\n",
    "print(amazon.newHelpful.sum())\n",
    "print(amazon.newHelfup.sum())\n",
    "print(amazon.helpful.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# assiging new colum\n",
    "y = amazon.newHelpful.values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_measures import BinaryClassificationPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26527, 'Neg': 337473, 'TP': 15784, 'TN': 329201, 'FP': 8272, 'FN': 10743, 'Accuracy': 0.94776098901098904, 'Precision': 0.65613568340538742, 'Recall': 0.59501639838654952, 'desc': 'svm'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X, y)\n",
    "joblib.dump(svm, 'svm.pkl') # pickle -- take a snapshop of fit\n",
    "\n",
    "svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "svm_performance.compute_measures()\n",
    "print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With new Label**: {'Pos': 46802, 'Neg': 317198, 'TP': 30841, 'TN': 298958, 'FP': 18240, 'FN': 15961, 'Accuracy': 0.90604120879120875, 'Precision': 0.62836943012571056, 'Recall': 0.65896756548865432, 'desc': 'svm'}\n",
    "Accuracy down, Precision up, Recall up\n",
    "\n",
    "**With Time Column**:{'Pos': 26527, 'Neg': 337473, 'TP': 16665, 'TN': 327315, 'FP': 10158, 'FN': 9862, 'Accuracy': 0.94499999999999995, 'Precision': 0.62129515714125938, 'Recall': 0.62822784332943793, 'desc': 'svm'}\n",
    "recall went up, percision down, accuracy down\n",
    "\n",
    "**With Summary Text Stats**: {'Pos': 26527, 'Neg': 337473, 'TP': 16207, 'TN': 328395, 'FP': 9078, 'FN': 10320, 'Accuracy': 0.94670879120879126, 'Precision': 0.64097290883923275, 'Recall': 0.61096241565197718, 'desc': 'svm'}\n",
    "\n",
    "Round1 Results: {'Pos': 26527, 'Neg': 337473, 'TP': 13988, 'TN': 325519, 'FP': 11954, 'FN': 12539, 'Accuracy': 0.93271153846153843, 'Precision': 0.53920283709814198, 'Recall': 0.52731179552908358, 'desc': 'svm'}\n",
    "\n",
    "Initial Results: {'FN': 14017, 'Precision': 0.53834237025561582, 'Neg': 337473, 'Pos': 26527, 'Recall': 0.47159497870094619, 'Accuracy': 0.93201923076923077, 'TN': 326745, 'desc': 'svm', 'TP': 12510, 'FP': 10728}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26527, 'Neg': 337473, 'TP': 17395, 'TN': 331026, 'FP': 6447, 'FN': 9132, 'Accuracy': 0.95720054945054944, 'Precision': 0.72959483264826774, 'Recall': 0.65574697478041244, 'desc': 'lgs'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "lgs.fit(X, y)\n",
    "joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "\n",
    "lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "lgs_performance.compute_measures()\n",
    "print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With new Label**: {'Pos': 46802, 'Neg': 317198, 'TP': 29416, 'TN': 306231, 'FP': 10967, 'FN': 17386, 'Accuracy': 0.9221071428571429, 'Precision': 0.72842532748929001, 'Recall': 0.62852014871159356, 'desc': 'lgs'}\n",
    "Accuracy down, Recall down, Precision up\n",
    "\n",
    "**With Time Column**: {'Pos': 26527, 'Neg': 337473, 'TP': 18630, 'TN': 328135, 'FP': 9338, 'FN': 7897, 'Accuracy': 0.95265109890109889, 'Precision': 0.66611842105263153, 'Recall': 0.7023033136050062, 'desc': 'lgs'}\n",
    "Accuracy up, Recall down, Percision up\n",
    "\n",
    "**With Summary Text Stats**:{'Pos': 26527, 'Neg': 337473, 'TP': 18907, 'TN': 326978, 'FP': 10495, 'FN': 7620, 'Accuracy': 0.9502335164835165, 'Precision': 0.64305149309570775, 'Recall': 0.712745504580239, 'desc': 'lgs'}\n",
    "\n",
    "Round1 Results: {'Pos': 26527, 'Neg': 337473, 'TP': 13226, 'TN': 330193, 'FP': 7280, 'FN': 13301, 'Accuracy': 0.94345879120879117, 'Precision': 0.64498195650053647, 'Recall': 0.49858634598710749, 'desc': 'lgs'}\n",
    "\n",
    "Initial results: {'FN': 13966, 'Precision': 0.61350981732929566, 'Neg': 337473, 'Pos': 26527, 'Recall': 0.47351754815848002, 'Accuracy': 0.9398928571428572, 'TN': 329560, 'desc': 'lgs', 'TP': 12561, 'FP': 7913}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26527, 'Neg': 337473, 'TP': 18741, 'TN': 297923, 'FP': 39550, 'FN': 7786, 'Accuracy': 0.86995604395604398, 'Precision': 0.32150760837865194, 'Recall': 0.70648772948316807, 'desc': 'nbs'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X, y)\n",
    "joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "\n",
    "nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "nbs_performance.compute_measures()\n",
    "print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - ended up adding summary text stats and the time column, but not altering the label\n",
    "\n",
    "**With new Label**: {'Pos': 54788, 'Neg': 309212, 'TP': 37485, 'TN': 272204, 'FP': 37008, 'FN': 17303, 'Accuracy': 0.85079395604395602, 'Precision': 0.50320164310740612, 'Recall': 0.68418266773746073, 'desc': 'nbs'}\n",
    "Accuracy down, Recall down, Precision up\n",
    "\n",
    "**With Time Column**:{'Pos': 26527, 'Neg': 337473, 'TP': 18591, 'TN': 299153, 'FP': 38320, 'FN': 7936, 'Accuracy': 0.87292307692307691, 'Precision': 0.32666795522833897, 'Recall': 0.70083311343159804, 'desc': 'nbs'}\n",
    "Precision slightly up, Accuracy slightly up, Recall slightly down\n",
    "\n",
    "**With Summary Text Stats**:{'Pos': 26527, 'Neg': 337473, 'TP': 18741, 'TN': 297923, 'FP': 39550, 'FN': 7786, 'Accuracy': 0.86995604395604398, 'Precision': 0.32150760837865194, 'Recall': 0.70648772948316807, 'desc': 'nbs'}\n",
    "\n",
    "Round1 Results: {'Pos': 26527, 'Neg': 337473, 'TP': 17006, 'TN': 297233, 'FP': 40240, 'FN': 9521, 'Accuracy': 0.86329395604395609, 'Precision': 0.29706879083254722, 'Recall': 0.641082670486674, 'desc': 'nbs'}\n",
    "\n",
    "Initial results: {'FN': 9525, 'Precision': 0.2958413085087872, 'Neg': 337473, 'Pos': 26527, 'Recall': 0.64093188072529872, 'Accuracy': 0.8626565934065934, 'TN': 297005, 'desc': 'nbs', 'TP': 17002, 'FP': 40468}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MODEL: Naive Bayes WITH ALPHA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB(alpha = 0.01)\n",
    "nbs.fit(X, y)\n",
    "joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "\n",
    "nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "nbs_performance.compute_measures()\n",
    "print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26527, 'Neg': 337473, 'TP': 10291, 'TN': 336967, 'FP': 506, 'FN': 16236, 'Accuracy': 0.95400549450549454, 'Precision': 0.95313513012873952, 'Recall': 0.38794435857805254, 'desc': 'rdg'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Ridge Regression Classifier\n",
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "rdg.fit(X, y)\n",
    "joblib.dump(rdg, 'rdg.pkl') # pickle\n",
    "\n",
    "rdg_performance = BinaryClassificationPerformance(rdg.predict(X), y, 'rdg')\n",
    "rdg_performance.compute_measures()\n",
    "print(rdg_performance.performance_measures) \n",
    "# lowest false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Time Column: {'Pos': 26527, 'Neg': 337473, 'TP': 10291, 'TN': 336967, 'FP': 506, 'FN': 16236, 'Accuracy': 0.95400549450549454, 'Precision': 0.95313513012873952, 'Recall': 0.38794435857805254, 'desc': 'rdg'}\n",
    "Accuracy up, Percision up, Recall up\n",
    "\n",
    "With Summary Text Stats:{'Pos': 26527, 'Neg': 337473, 'TP': 10137, 'TN': 336988, 'FP': 485, 'FN': 16390, 'Accuracy': 0.95364010989010994, 'Precision': 0.95434004895499902, 'Recall': 0.38213895276510723, 'desc': 'rdg'}\n",
    "\n",
    "Round1 results: {'TP': 7873, 'desc': 'rdg', 'FP': 512, 'TN': 336961, 'Recall': 0.29679194782674256, 'Precision': 0.93893858079904591, 'Neg': 337473, 'Pos': 26527, 'FN': 18654, 'Accuracy': 0.94734615384615384}\n",
    "\n",
    "Initial results: {'FN': 18753, 'Precision': 0.93258157389635321, 'Neg': 337473, 'Pos': 26527, 'Recall': 0.29305990123270631, 'Accuracy': 0.94693681318681322, 'TN': 336911, 'desc': 'rdg', 'TP': 7774, 'FP': 562}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26527, 'Neg': 337473, 'TP': 17278, 'TN': 325603, 'FP': 11870, 'FN': 9249, 'Accuracy': 0.94198076923076923, 'Precision': 0.59276794291203516, 'Recall': 0.65133637426018776, 'desc': 'prc'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Perceptron\n",
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X, y)\n",
    "joblib.dump(prc, 'prc.pkl') # pickle\n",
    "\n",
    "prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "prc_performance.compute_measures()\n",
    "print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Time Column:{'Pos': 26527, 'Neg': 337473, 'TP': 17278, 'TN': 325603, 'FP': 11870, 'FN': 9249, 'Accuracy': 0.94198076923076923, 'Precision': 0.59276794291203516, 'Recall': 0.65133637426018776, 'desc': 'prc'}\n",
    "Accuracy slightly down, Percision slightly down, Recall up\n",
    "\n",
    "With Summary Text Stats:{'Pos': 26527, 'Neg': 337473, 'TP': 16965, 'TN': 326025, 'FP': 11448, 'FN': 9562, 'Accuracy': 0.94228021978021981, 'Precision': 0.59708584098827999, 'Recall': 0.63953707543257809, 'desc': 'prc'}\n",
    "\n",
    "Round1 results: {'TP': 13255, 'desc': 'prc', 'FP': 9337, 'TN': 328136, 'Recall': 0.49967957175707767, 'Precision': 0.58671211048158645, 'Neg': 337473, 'Pos': 26527, 'FN': 13272, 'Accuracy': 0.93788736263736261}\n",
    "\n",
    "Initial results: {'FN': 13888, 'Precision': 0.52847466131460108, 'Neg': 337473, 'Pos': 26527, 'Recall': 0.47645794850529649, 'Accuracy': 0.93086538461538459, 'TN': 326196, 'desc': 'prc', 'TP': 12639, 'FP': 11277}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmYFeWZ9/Hvjz3IpkJeF0B01AiI\nAragYBTeEAcYR9SoSMBoMPJqhsRrjCYkjhnHjJNo8ipjgjG4xCUGlKCIW8wyokFRBDUqRkZwUHFD\nxQVEVOCeP6oaDu3p6tNNV59D8/tcV11dy1NV9ymac/fzPFVPKSIwMzOrTYtyB2BmZpXNicLMzDI5\nUZiZWSYnCjMzy+REYWZmmZwozMwskxOFNWuSTpc0v9xxZJG0RNKwxi5r1licKKzRSFoh6SNJayW9\nIekGSR1qlBki6b8krZH0vqS7JPWpUaaTpKmSXk6PtSxd7ppz/PMkfaMe5XtJCkmttuW8EdE3IuY1\ndtmmkP4b/3u547B8OVFYY/vHiOgA9AcGAN+v3iDpcOAPwJ3AHsDewF+BhyXtk5ZpA/wZ6AuMBDoB\nQ4B3gEFN9zEax7YmEbOKEBGePDXKBKwARhQsXwbcU7D8F+CqIvvdB9yUzn8DeBPoUI/zBvBt4EXg\nbeCnQIt02+nA/IKyQ4DHgffTn0PS9ZcAG4H1wFrgFyWc9+X03GvT6fD0fA8DVwCrgX8H/g74L5Jk\n9zZwC9Cl2HUDLgJuA24C1gBLgKoGlh0IPJlumwXcCvx7LZ9lX+DB9Lq8DdxasO0A4I/p51kKnJyu\nnwR8CnySfv67yv076CmfyTUKy4Wk7sAoYFm63J7kS3pWkeK3AV9O50cAv4+ItfU85fFAFcmX4xhg\nYpGYdgHuAa4EdgUuB+6RtGtEXECSyCZHRIeImJzuc7ekKbWc88j0Z5d0nwXp8mCSpPV5kgQk4Mck\ntajeQA+SL/naHAvMBLoAc4Ff1LdsWjO7A7gB2AWYQXKNavMjktrezkB34OfpcXYiSRK/TT/POOAq\nSX0jYjpJ0rss/fz/mHF82445UVhjmyNpDfAKsAr413T9LiS/b68X2ed1oLr/YddaytTl0ohYHREv\nA1NJvtBq+gfghYi4OSI2RMQM4Hmg1i+4iDgmIn5Sz1hei4ifp+f4KCKWRcQfI+LjiHiLJEEdlbH/\n/Ii4NyI2AjcDBzeg7GFAK+DKiPg0Im4HFmYc51NgL2CPiFgfEdU3ABwDrIiIX6ef5wlgNnBiHdfA\nmhEnCmtsx0VER2AYSZNFdQJ4F9gE7F5kn91JmjsgaZ4pVqYurxTMv0Ty13tNe6TbqFF2zwacr9RY\nkPR5STMlvSrpA+A3bLkuxbxRML8OaJfR11Fb2T2AVyOicNTPreKq4bskNZ+F6Z1V1TWyvYDBkt6r\nnoDxwG4Zx7JmxonCchERD5I0e/wsXf4QWACcVKT4ySQd2AB/Av4+bfKojx4F8z2B14qUeY3ki48a\nZV+tDrue56ytfM31P07XHRQRnYAJJF/KeXod2FNS4Xl61FY4It6IiDMjYg/g/5E0L+1LklwejIgu\nBVOHiDi7etfcPoFVDCcKy9NU4MuS+qfLU4DTJH1bUkdJO6e3Vh4O/Fta5maSL6fZkg6Q1ELSrpJ+\nIGl0xrnOT4/XAziHpOO2pnuB/SV9VVIrSWOBPsDd6fY3gX3q8fneIqkl1bVPR5LO3vck7QmcX49z\nNNQCks75yelnHUPGXWOSTkr7lSCp/UW6/90k1+xUSa3T6VBJvdOy9b1mth1yorDcpO3xNwEXpsvz\ngb8HTiD5i/clkltoj4iIF9IyH5N0aD9P0on6AUnbelfgsYzT3QksBp4i6bC+rkg875C0uX+HpInr\nu8AxEVHd7PWfwImS3pV0JYCk+yT9oJbPt46ks/rhtFnmsFpi+zeSTvb309huz/gcjSIiPiG5zmcA\n75HUYu4GPq5ll0OBxyStJekUPyci/ici1gBHA6eQ1MjeAC4F2qb7XQf0ST//nLw+j5WXtm7CNNv+\nSApgv4hYVu5YKpmkx4CrI+LX5Y7Fti+uUZg1U5KOkrRb2vR0GnAQ8Ptyx2Xbn9wShaTrJa2S9Gwt\n2yXpynR4hqclDcwrFrMd1BdInnx/n6S57cSIaMitx7aDy63pSdKRJB14N0XEgUW2jwa+BYwmeUDp\nPyNicC7BmJlZg+VWo4iIh0ge+a/NGJIkEhHxKNBFUkPunzczsxyVc8CyPdn6AaCV6brPVI0lTSIZ\nV4addtrpkAMOOKBJAjQzay4WL178dkR0a8i+5UwUxR44KtoOlo4pMx2gqqoqFi1alGdcZmbNjqSa\noxKUrJx3Pa1k6ydFu1P8aVozMyujciaKucDX0rufDgPe9x0ZZmaVJ7emJ0kzSAaG6yppJckooq0B\nIuJqkuEURpMMQ70O+HpesZiZWcPlligiotgwz4XbA/invM5vZmaNw09mm5lZJicKMzPL5ERhZmaZ\nnCjMzCyTE4WZmWVyojAzs0xOFGZmlsmJwszMMjlRmJlZJicKMzPL5ERhZmaZnCjMzCyTE4WZmWVy\nojAzs0xOFGZmlsmJwszMMjlRmJlZJicKMzPL5ERhZmaZnCjMzCyTE4WZmWVyojAzs0xOFGZmlsmJ\nwszMMjlRmJlZJicKMzPL5ERhZmaZnCjMzCyTE4WZmWVyojAzs0xOFGZmlsmJwszMMjlRmJlZJicK\nMzPL5ERhZmaZck0UkkZKWippmaQpRbb3lPSApCclPS1pdJ7xmJlZ/eWWKCS1BKYBo4A+wDhJfWoU\n+xfgtogYAJwCXJVXPGZm1jB51igGAcsi4sWI+ASYCYypUSaATul8Z+C1HOMxM7MGyDNR7Am8UrC8\nMl1X6CJggqSVwL3At4odSNIkSYskLXrrrbfyiNXMzGqRZ6JQkXVRY3kccENEdAdGAzdL+kxMETE9\nIqoioqpbt245hGpmZrXJM1GsBHoULHfns01LZwC3AUTEAqAd0DXHmMzMrJ7yTBSPA/tJ2ltSG5LO\n6rk1yrwMfAlAUm+SROG2JTOzCpJbooiIDcBk4H7gbyR3Ny2RdLGkY9Ni3wHOlPRXYAZwekTUbJ4y\nM7MyapXnwSPiXpJO6sJ1PyyYfw4YmmcMZma2bfxktpmZZXKiMDOzTE4UZmaWyYnCzMwyOVGYmVkm\nJwozM8vkRGFmZpmcKMzMLFOzTRQdOnQodwibDRs2jEWLFpU7DDOzBmm2icLMzBpHs08UmzZt4pvf\n/CZ9+/blmGOOYfTo0fzud78DYMqUKfTp04eDDjqI8847b5vPtWLFCnr37s2ZZ55J3759Ofroo/no\no48A+M1vfsOQIUM48MADWbhwIQAPPvgg/fv3p3///gwYMIA1a9ZscwxmZo0t17GeKsHtt9/OihUr\neOaZZ1i1ahW9e/dm4sSJrF69mjvuuIPnn38eSbz33nuNcr4XXniBGTNmcM0113DyyScze/ZsAD78\n8EMeeeQRHnroISZOnMizzz7Lz372M6ZNm8bQoUNZu3Yt7dq1a5QYzMwaU/OqUdxyC/TqBS1awLp1\ncMstzJ8/n5NOOokWLVqw2267MXz4cAA6depEu3bt+MY3vsHtt99O+/btt/2cRxzB3l270r9/fwAO\nOeQQVqxYAcC4ceMAOPLII/nggw947733GDp0KOeeey5XXnkl7733Hq1aNfu8bWbboeaTKG65BSZN\ngpdegohkmjSJ+NvfihZv1aoVCxcu5Ctf+Qpz5sxh5MiR237OV1+l7apVyXqgZcuWbNiwAQBp6xf+\nSWLKlClce+21fPTRRxx22GE8//zz9Y/BzCxnzSdRXHBBUosotG4dRzzxBLNnz2bTpk28+eabzJs3\nD4C1a9fy/vvvM3r0aKZOncpTTz3VOOeMSNbXcOuttwIwf/58OnfuTOfOnVm+fDn9+vXje9/7HlVV\nVU4UZlaRmk9bx8svF139lbff5s/du3PggQey//77M3jwYDp37syaNWsYM2YM69evJyK44oorGu2c\nxdbvvPPODBkyhA8++IDrr78egKlTp/LAAw/QsmVL+vTpw6hRo+ofg5lZzrS9vVCuqqoqij6T0KtX\n0gRU0157sfbZZ+nQoQPvvPMOgwYN4uGHH2a33Xbb9mAyzknaN2FmVgkkLY6IqobsW2fTk6TPSfq+\npKvT5X0lVd6fvpdcAjU7pNu3h0su4ZhjjqF///588Ytf5MILL2ycJFHHOc3MmotSmp6uB54BjkiX\nXwNmAfflFVSDjB+f/LzggqTpp2fP5At7/HjmVW9rwnOamTUXdTY9SVoUEVWSnoyIAem6pyKif5NE\nWEOtTU9mZlarXJuegE8ktQMiPdnewCcNOVkl27hxY7lDMDOrSKUkih8Bvwe6S7oReAD4Qa5RNbIV\nK1ZwwAEHcNppp3HQQQdx4oknsm7dOnr16sXFF1/MEUccwaxZs1i2bBkjRozg4IMPZuDAgSxfvrzc\noZuZlV2dfRQRcZ+kRcAQQMD5EbEq98ga2dKlS7nuuusYOnQoEydO5KqrrgKgXbt2zJ8/H4DBgwcz\nZcoUjj/+eNavX8+mTZvKGbKZWUUo5a6nP0TEWxFxZ0TMiYhVkv7QFMFtkxpDa/TYdVeGDh0KwIQJ\nEzYnh7FjxwKwZs0aXn31VY4//nggSSANHtbDzKwZqTVRSGojqRPwfyR1lNQpnboDPZsuxAYoMrSG\nVq/ePLQGbBlSY6eddgJge3uexMysqWTVKP4JWAIckP6snu4Hrs4/tG1QZGiNlyNYkA4lPmPGDI44\n4oittnfq1Inu3bszZ84cAD7++GPW1Ryew8xsB1RrooiIKyKiB/C9iOgZET3SqW9ETG3CGOsvHULj\nQ+AfgFFAW+AHb7xBly5dWL16NWeffTbr169nfPrMQ4cOHejXrx+nnnoqHTt25OCDD2b48OHss88+\nzJ07t1yfxMys7Orso4iIqZIOkHSCpK9WT00RXIP1TFrGfg/sQfJk4L7AnB496NSpEzfddBPt27fn\n+OOP59RTTwWS90WccMIJrFmzhhEjRtCzZ0/mz5/PHXfcwQ9/+MNyfRIzs7IrpTP7X4DpJM1No4Cp\nwIk5x9Vwt9wCa9cC0A/4E/ATYJ1E5x//mJEjR3LXXXexYcMG7rnnHsaMGQNAmzZtNg813q9fP446\n6ihat25Nv379Nr9TwsxsR1TKEB5jgf7AExFxqqTdgV/lG1YDVXdip30L+wOLgXs7dODZPfbg4uXL\nGTt2LNOmTWOXXXbh0EMPpWPHjgC0bt16cwd3ixYtaNu27eb56ndKmJntiEp54O6jiNgIbJDUEXgD\n2CffsBqoRif2a0B7YMKuu3LepZfyxBNPMGzYMJ544gmuueaazbfGmplZ7UqpUTwpqQvJ4ICLgA+A\nJ3KNqqFqvAfiGeB8oMVLL9H6kkv45S9/ScuWLTnmmGO44YYbuPHGG8sSppnZ9iRzUEAlbTG7RcTr\n6fK+QKeIKFuiyBwU0O+HMDMrKrdBASPJIncXLC8rZ5Kok98PYWbW6Erpo1goaWBDDi5ppKSlkpZJ\nmlJLmZMlPSdpiaTfNuQ8m40fD9OnJzUIKfk5fbrfD2Fmtg1KeR/FM0BvYDnJM2wiqWxkJg9JLYH/\nBr4MrAQeB8ZFxHMFZfYDbgP+b0S8K+nzdQ046PdRmJnV37Y0PZXSmX1cQw4MDAKWRcSLAJJmAmOA\n5wrKnAlMi4h3AbbHUWnNzJq7UoYZb+hLGfYEXilYXgkMrlFmfwBJDwMtgYsi4vc1DyRpEjAJoGfP\nyh6P0MysuSmlj6KhVGRdzXauVsB+wDBgHHBteivu1jtFTI+Iqoio6tatW6MHamZmtcszUawEehQs\ndyd5Bq5mmTsj4tOI+B9gKUniMDOzClFSopDUXdLwdL6tpJ1K2O1xYD9Je0tqA5wC1ByGdQ5Qfdyu\nJE1RL5YavJmZ5a+UQQEnknzBX5uu2gu4s679ImIDMJnk/RV/A26LiCWSLpZ0bFrsfuAdSc+RvIv7\n/Ih4p/4fw8zM8lLK7bFPkdzB9FhEDEjXPR0RBzVBfJ/h22PNzOovtyezU+sj4pOCk7WkeEe1mZk1\nQ6UkioclfRdol/ZT3ErBsB5mZta8lZIovgusAZ4HzgH+DFyQZ1BmZlY5SnkyezRwbUT8Mu9gzMys\n8pRSozgZWCbp15L+Pu2jMDOzHUSdiSIiTiV5vuEuYCLwoqSr8w7MzMwqQylNT0TEx5LuBD4iGZPp\nZOCsPAMzM7PKUMoDdyMkXUsyzPgE4CZgt7wDMzOzylBKjeIsYCbwrYj4KOd4zMyswpQyzPiJTRGI\nmZlVploThaQHI+IoSe+y9fDg1W+42yX36MzMrOyyahTD059dmyIQMzOrTLV2ZkfEpnT2uojYWDgB\n1zVNeGZmVm6lPHC31Six6QN3h+YTjpmZVZpaE4Wk76X9EwdJWp1O7wJvAfc2WYRmZlZWWTWKy4Bu\nwBXpz25A14jYJSLOb4rgzMys/LI6s/eNiBck3Qz0rV4pJa+iiIinc47NzMwqQFaimAKcAUwrsi2A\nI3OJyMzMKkqtiSIizkh/frHpwjEzs0pTylhPJ0jqmM5PkXSbpIPzD83MzCpBKbfHXhQRayQNAf6R\n5FWov8o3LDMzqxSlJIqN6c9jgKsiYjbQNr+QzMyskpQyeuzrkqYBo4BDJLWhtARjZmbNQKmvQn0Q\nGB0R75KM/TQl16jMzKxilPIq1LXAc8AwSWcBO0fEfblHZmZmFaGUu54mA7cBPdPpNknfzDswMzOr\nDKX0UUwCBqU1CyT9B/AIcFWegZmZWWUopY9CwKcFy5+m68zMbAdQSo3iZuBRSbNJEsRxwI25RmVm\nZhWjlHdmXybpAaB6KI+zIuLxfMMyM7NKUUqNAuDjdNqU/jQzsx1EKXc9XQDMAHYHugO/lfT9vAMz\nM7PKUEqNYgJwSESsA5B0CbAY+HGegZmZWWUo5a6nl9g6obQCXswnnG13ww03MHny5HKHYWbWbJRS\no1gHLJF0P8kLi44G5ku6HCAizs0xvjpFBBFBixYefsrMLA+lJIp70qnao6UeXNJI4D+BlsC1EfGT\nWsqdCMwCDo2IRXUdd8WKFYwaNYrhw4ezYMECjjvuOG655RZ233139t9/f9q2TQa3Xb58OePHj2fj\nxo2MGjWKyy+/nLVr15YavpmZUdrtsdc15MCSWpK8RvXLwErgcUlzI+K5GuU6At8GHqvP8ZcuXcqv\nf/1rLrzwQgYPHszixYvp3Lkzw4cPZ8CAAQCcc845nHPOOYwbN46rr766IR/DzGyHl2d7zSBgWUS8\nGBGfADOBMUXK/Qi4DFhf0lGfeQb23pu9WrTgsOXLeeyxxxg2bBjdunWjTZs2jB07dnPRBQsWcNJJ\nJwHw1a9+dRs/jpnZjinPRLEn8ErB8sp03WaSBgA9IuLurANJmiRpkaRFfPIJADtt3AiTJsGDDyJ5\nRBEzs7yUnCgk1fetdsW+vaPgeC2AK4Dv1HWgiJgeEVURUbXVhnXrGDxrFvPmzeOdd97h008/Zdas\nWZs3H3bYYcyePRuAmTNn1jN8MzOD0h64GyTpGeCFdPlgST8v4dgrgR4Fy92B1wqWOwIHAvMkrQAO\nA+ZK2joZ1GH3117joosu4vDDD2fEiBEMHDhw87apU6dy+eWXM2jQIF5//XU6d+5cn0ObmRmgiMgu\nID0KjAXmRMSAdN2zEXFgHfu1Av4b+BLwKvA48NWIWFJL+XnAeXXd9VQlbV1gr71gxYqiZdetW8fn\nPvc5JDFz5kxmzJjBnXfemXV4M7NmSdLiz7TKlKiU22NbRMRLNfoBNta1U0RsSF96dD/J7bHXR8QS\nSRcDiyJibkMC3kr79nDJJbVuXrx4MZMnTyYi6NKlC9dff/02n9LMbEdTSo1iNnApcDVwKPAtYGhE\nnJR/eJ9V1bZtLPr0U+jZM0kS48eXIwwzs+1K3jWKs4ErSV6D+ibwp3RdefTrB4vqfCbPzMwaSSkP\n3K0CTmmCWMzMrALVmSgkXUPBba3VImJSLhGZmVlFKaXp6U8F8+2A49n6QTozM2vGSml6urVwWdLN\nwB9zi8jMzCpKQ4bw2BvYq7EDMTOzylRKH8W7bOmjaAGsBqbkGZSZmVWOzESh5Cm7g0merAbYFHU9\neGFmZs1KZtNTmhTuiIiN6eQkYWa2gymlj2KhpIF1FzMzs+ao1qYnSa0iYgNwBHCmpOXAhyTDh0dE\nOHmYme0AsvooFgIDgeOaKBYzM6tAWYlCABGxvIliMTOzCpSVKLpJOre2jRFxeQ7xmJlZhclKFC2B\nDhR/pamZme0gshLF6xFxcZNFYmZmFSnr9ljXJMzMLDNRfKnJojAzs4pVa6KIiNVNGYiZmVWmhowe\na2ZmOxAnCjMzy+REYWZmmZwozMwskxOFmZllcqIwM7NMThRmZpbJicLMzDI5UZiZWSYnCjMzy+RE\nYWZmmZwozMwskxOFmZllcqIwM7NMThRmZpYp10QhaaSkpZKWSZpSZPu5kp6T9LSkP0vaK894zMys\n/nJLFJJaAtOAUUAfYJykPjWKPQlURcRBwO+Ay/KKx8zMGibPGsUgYFlEvBgRnwAzgTGFBSLigYhY\nly4+CnTPMR4zM2uAPBPFnsArBcsr03W1OQO4r9gGSZMkLZK06K233mrEEM3MrC55JgoVWRdFC0oT\ngCrgp8W2R8T0iKiKiKpu3bo1YohmZlaXVjkeeyXQo2C5O/BazUKSRgAXAEdFxMc5xmNmZg2QZ43i\ncWA/SXtLagOcAswtLCBpAPAr4NiIWJVjLGZm1kC5JYqI2ABMBu4H/gbcFhFLJF0s6di02E+BDsAs\nSU9JmlvL4czMrEzybHoiIu4F7q2x7ocF8yPyPL+ZmW07P5ltZmaZnCjMzCyTE4WZmWVyojAzs0xO\nFGZmlsmJwszMMjlRmJlZJicKMzPL5ERhZmaZnCjMzCyTE4WZmWVyojAzs0xOFGZmlsmJwszMMjlR\nmJlZJicKMzPL5ERhZmaZnCjMzCyTE4WZmWVyojAzs0xOFGZmlsmJwszMMjlRmJlZJicKMzPL5ERh\nZmaZnCjMzCyTE4WZmWVyojAzs0xOFGZmlsmJwszMMjlRmJlZJicKMzPL5ERhZmaZnCjMzCyTE4WZ\nmWXKNVFIGilpqaRlkqYU2d5W0q3p9sck9cozHjMzq7/cEoWklsA0YBTQBxgnqU+NYmcA70bEvsAV\nwKV5xWNmZg2TZ41iELAsIl6MiE+AmcCYGmXGADem878DviRJOcZkZmb11CrHY+8JvFKwvBIYXFuZ\niNgg6X1gV+DtwkKSJgGT0sWPJT2bS8Tbn67UuFY7MF+LLXwttvC12OILDd0xz0RRrGYQDShDREwH\npgNIWhQRVdse3vbP12ILX4stfC228LXYQtKihu6bZ9PTSqBHwXJ34LXaykhqBXQGVucYk5mZ1VOe\nieJxYD9Je0tqA5wCzK1RZi5wWjp/IvBfEfGZGoWZmZVPbk1PaZ/DZOB+oCVwfUQskXQxsCgi5gLX\nATdLWkZSkzilhENPzyvm7ZCvxRa+Flv4Wmzha7FFg6+F/Ae8mZll8ZPZZmaWyYnCzMwyVWyi8PAf\nW5RwLc6V9JykpyX9WdJe5YizKdR1LQrKnSgpJDXbWyNLuRaSTk5/N5ZI+m1Tx9hUSvg/0lPSA5Ke\nTP+fjC5HnHmTdL2kVbU9a6bElel1elrSwJIOHBEVN5F0fi8H9gHaAH8F+tQo803g6nT+FODWcsdd\nxmsxHGifzp+9I1+LtFxH4CHgUaCq3HGX8fdiP+BJYOd0+fPljruM12I6cHY63wdYUe64c7oWRwID\ngWdr2T4auI/kGbbDgMdKOW6l1ig8/McWdV6LiHggItali4+SPLPSHJXyewHwI+AyYH1TBtfESrkW\nZwLTIuJdgIhY1cQxNpVSrkUAndL5znz2ma5mISIeIvtZtDHATZF4FOgiafe6jlupiaLY8B971lYm\nIjYA1cN/NDelXItCZ5D8xdAc1XktJA0AekTE3U0ZWBmU8nuxP7C/pIclPSppZJNF17RKuRYXARMk\nrQTuBb7VNKFVnPp+nwD5DuGxLRpt+I9moOTPKWkCUAUclWtE5ZN5LSS1IBmF+PSmCqiMSvm9aEXS\n/DSMpJb5F0kHRsR7OcfW1Eq5FuOAGyLi/0s6nOT5rQMjYlP+4VWUBn1vVmqNwsN/bFHKtUDSCOAC\n4NiI+LiJYmtqdV2LjsCBwDxJK0jaYOc20w7tUv+P3BkRn0bE/wBLSRJHc1PKtTgDuA0gIhYA7UgG\nDNzRlPR9UlOlJgoP/7FFndcibW75FUmSaK7t0FDHtYiI9yOia0T0ioheJP01x0ZEgwdDq2Cl/B+Z\nQ3KjA5K6kjRFvdikUTaNUq7Fy8CXACT1JkkUbzVplJVhLvC19O6nw4D3I+L1unaqyKanyG/4j+1O\nidfip0AHYFban/9yRBxbtqBzUuK12CGUeC3uB46W9BywETg/It4pX9T5KPFafAe4RtI/kzS1nN4c\n/7CUNIOkqbFr2h/zr0BrgIi4mqR/ZjSwDFgHfL2k4zbDa2VmZo2oUpuezMysQjhRmJlZJicKMzPL\n5ERhZmaZnCjMzCyTE4VVLEkbJT1VMPXKKNurthEzm5qkKklXpvPDJA0p2HaWpK81YSz9m+tIqdZ0\nKvI5CrPURxHRv9xB1Ff6gF/1Q37DgLXAI+m2qxv7fJJapeOdFdOfZFiXexv7vLbjcI3CtitpzeEv\nkp5IpyFFyvSVtDCthTwtab90/YSC9b+S1LLIviskXZqWWyhp33T9Xkre9VH9zo+e6fqTJD0r6a+S\nHkrXDZN0d1oDOgv45/ScX5R0kaTzJPWWtLDG53o6nT9E0oOSFku6v9jonpJukHS5pAeASyUNkvSI\nkvctPCLpC+lTyhcDY9Pzj5W0k5J3Fjyeli02+q7Z1so9fronT7VNJE8TP5VOd6Tr2gPt0vn9SJ68\nBehFOgY/8HNgfDrfBvgc0Bu4C2idrr8K+FqRc64ALkjnvwbcnc7fBZyWzk8E5qTzzwB7pvNd0p/D\nCva7CDiv4Pibl9PPtU86/z3gX0ieon0E6JauH0vypHHNOG8A7gZapsudgFbp/Ahgdjp/OvCLgv3+\nA5hQHS/w38BO5f639lTZk5srDI22AAACKElEQVSerJIVa3pqDfxCUn+SRLJ/kf0WABdI6g7cHhEv\nSPoScAjweDrMyeeA2sbFmlHw84p0/nDghHT+ZpL3XQA8DNwg6Tbg9vp8OJJB6k4GfkKSEMYCXyAZ\n2PCPaZwtgdrG4pkVERvT+c7AjWntKUiHbSjiaOBYSeely+2AnsDf6hm77UCcKGx788/Am8DBJE2n\nn3k5UUT8VtJjwD8A90v6BsnwyjdGxPdLOEfUMv+ZMhFxlqTB6bmeShNYqW4lGZ/r9uRQ8YKkfsCS\niDi8hP0/LJj/EfBARByfNnnNq2UfAV+JiKX1iNN2cO6jsO1NZ+D1SN4jcCrJX9xbkbQP8GJEXEky\nWuZBwJ+BEyV9Pi2zi2p/t/jYgp8L0vlH2DLw5Hhgfnqcv4uIxyLih8DbbD2EM8AakuHPPyMilpPU\nii4kSRqQDAXeTck7E5DUWlLfWuIs1Bl4NZ0/PeP89wPfUlpdUTLysFkmJwrb3lwFnCbpUZJmpw+L\nlBkLPCvpKeAAklc/PkfSB/CHtNP4j0Btr4Bsm9ZIziGpwQB8G/h6uu+p6TaAn0p6Jr019yGS9zUX\nugs4vrozu8i5bgUmsOVdCZ+QDJt/qaS/kvRjfKbDvojLgB9Lepitk+cDQJ/qzmySmkdr4Ok05h+V\ncGzbwXn0WLMCSl54VBURb5c7FrNK4RqFmZllco3CzMwyuUZhZmaZnCjMzCyTE4WZmWVyojAzs0xO\nFGZmlul/AXYiQaFVegMCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1517cfa048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [svm_performance, lgs_performance, nbs_performance, rdg_performance, prc_performance]\n",
    "# fits = [svm_performance, lgs_performance, rdg_performance, prc_performance]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'ro')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "going with naive bayes which has the highest true positive rate/recall/sensitivity (ie TP/Pos) even though it has a higher false positive rate (FP/Neg). I make this conscious choice because I already feel that our helpful tag is undertagging helpful comments and therefore am hoping that the false positives will turn out to be true once the label is corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking into model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First checking to make sure that the records haven't changed order through our feature prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.89568424,   6.55724466,   5.08151649, ...,   0.35056962,\n",
       "        18.63337977,   0.02204802])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data contains the non-zero values of the matrix in the order\n",
    "# in which they would be encountered if we walked along the rows\n",
    "X.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,       54,       78, ..., 21374915, 21374968, 21374998], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indptr[i] tells us where the i-th columns begins\n",
    "X.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.48956842e+01   6.55724466e+00   5.08151649e+00   1.22926434e+01\n",
      "   8.03240986e+00   1.99238944e+00   1.68846160e+00   2.12097122e+01\n",
      "   3.90392404e+01   2.15880739e+00   7.61654332e+00   2.59807575e+00\n",
      "   1.51064980e+01   6.82210633e+00   1.83380589e+00   2.26335734e+00\n",
      "   7.83523357e-01   5.18581697e+00   1.32746996e+01   1.47093897e+00\n",
      "   2.95842586e+00   2.51776555e+00   9.37606942e+00   2.10232653e+00\n",
      "   3.06932959e+00   1.79068982e+00   4.11817557e+01   3.57847451e+00\n",
      "   1.39716877e+00   9.97363014e+00   5.25181349e+00   6.38501371e+00\n",
      "   1.29612679e+00   1.29174365e+00   2.22281755e+00   1.12766272e+00\n",
      "   7.33673909e+00   5.36511235e+00   2.91370399e+00   5.65908425e+00\n",
      "   1.86752994e+01   2.26372027e+00   6.03368088e+00   1.35635364e+00\n",
      "   7.60030880e+01   4.16076849e+00   2.59916757e+00   2.59960588e+00\n",
      "   5.78715159e+00   3.81202989e+00   7.48331294e-01   1.96875984e+01\n",
      "   2.64576194e-01   2.12123168e-02]\n"
     ]
    }
   ],
   "source": [
    "# gives us all the non-zero values of our first row\n",
    "print(X.data[X.indptr[0]:X.indptr[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2268,   4219,   6168, ..., 131073, 131074, 131075], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(X).shape\n",
    "# how do we know the order hasn't changed??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add predictions to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon['svm_predictions'] = svm.predict(X)\n",
    "amazon['nbs_predictions'] = nbs.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "      <th>svm_predictions</th>\n",
       "      <th>nbs_predicitons</th>\n",
       "      <th>nbs_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325101</td>\n",
       "      <td>150237</td>\n",
       "      <td>150238</td>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>A25KKXUQQ0OLWB</td>\n",
       "      <td>Lynn Ellingwood \"The ESOL Teacher\"</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1282348800</td>\n",
       "      <td>My Cats' Favorite Food!</td>\n",
       "      <td>When this food came out, my cats went crazy th...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>376619</td>\n",
       "      <td>213859</td>\n",
       "      <td>213860</td>\n",
       "      <td>B0000DCXCM</td>\n",
       "      <td>A1NCFPKB690L3G</td>\n",
       "      <td>Anna R. Brown</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1267920000</td>\n",
       "      <td>Too salty</td>\n",
       "      <td>The almonds in this mix were great - crunchy w...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244837</td>\n",
       "      <td>385642</td>\n",
       "      <td>385643</td>\n",
       "      <td>B007FRCNCE</td>\n",
       "      <td>A2EG7IWLQIXQMX</td>\n",
       "      <td>Zachariah Green \"Zachariah Green\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1300320000</td>\n",
       "      <td>Great Tea!</td>\n",
       "      <td>This is one of my favorites... Most relaxing t...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270468</td>\n",
       "      <td>102738</td>\n",
       "      <td>102739</td>\n",
       "      <td>B002L96X68</td>\n",
       "      <td>AAUICTIUBVU7R</td>\n",
       "      <td>Roy Berger \"Everyman\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1341446400</td>\n",
       "      <td>YUM, YUM, YUM TERRIFIC</td>\n",
       "      <td>Great flavor and plenty of it! It's like eatin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42280</td>\n",
       "      <td>313513</td>\n",
       "      <td>313514</td>\n",
       "      <td>B000FNJ69S</td>\n",
       "      <td>A3S62P7QTO4P8V</td>\n",
       "      <td>Chad Susott \"Sparty DDS\"</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1283040000</td>\n",
       "      <td>Great with Sushi</td>\n",
       "      <td>I'm not a wasabi connoisseur by any means but ...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
       "0      325101        150237  150238  B001STX13U  A25KKXUQQ0OLWB   \n",
       "1      376619        213859  213860  B0000DCXCM  A1NCFPKB690L3G   \n",
       "2      244837        385642  385643  B007FRCNCE  A2EG7IWLQIXQMX   \n",
       "3      270468        102738  102739  B002L96X68   AAUICTIUBVU7R   \n",
       "4       42280        313513  313514  B000FNJ69S  A3S62P7QTO4P8V   \n",
       "\n",
       "                          ProfileName  HelpfulnessNumerator  \\\n",
       "0  Lynn Ellingwood \"The ESOL Teacher\"                    10   \n",
       "1                       Anna R. Brown                     1   \n",
       "2   Zachariah Green \"Zachariah Green\"                     2   \n",
       "3               Roy Berger \"Everyman\"                     0   \n",
       "4            Chad Susott \"Sparty DDS\"                     3   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                  Summary  \\\n",
       "0                      10      5  1282348800  My Cats' Favorite Food!   \n",
       "1                       2      1  1267920000                Too salty   \n",
       "2                       2      5  1300320000               Great Tea!   \n",
       "3                       0      5  1341446400   YUM, YUM, YUM TERRIFIC   \n",
       "4                       4      5  1283040000         Great with Sushi   \n",
       "\n",
       "                                                Text  helpScore  helpful  \\\n",
       "0  When this food came out, my cats went crazy th...       1.00     True   \n",
       "1  The almonds in this mix were great - crunchy w...       0.50    False   \n",
       "2  This is one of my favorites... Most relaxing t...       1.00    False   \n",
       "3  Great flavor and plenty of it! It's like eatin...        NaN    False   \n",
       "4  I'm not a wasabi connoisseur by any means but ...       0.75    False   \n",
       "\n",
       "   svm_predictions  nbs_predicitons  nbs_predictions  \n",
       "0             True            False            False  \n",
       "1            False            False            False  \n",
       "2            False            False            False  \n",
       "3            False            False            False  \n",
       "4             True             True             True  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head()\n",
    "# amazon.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at cases where at least 1 indicator said true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take all rows where at least one tagged as true\n",
    "someoneSaysTrue = amazon[amazon.helpful | amazon.svm_predictions | amazon.nbs_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72652, 17)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someoneSaysTrue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "      <th>svm_predictions</th>\n",
       "      <th>nbs_predicitons</th>\n",
       "      <th>nbs_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325101</td>\n",
       "      <td>150237</td>\n",
       "      <td>150238</td>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>A25KKXUQQ0OLWB</td>\n",
       "      <td>Lynn Ellingwood \"The ESOL Teacher\"</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1282348800</td>\n",
       "      <td>My Cats' Favorite Food!</td>\n",
       "      <td>When this food came out, my cats went crazy th...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42280</td>\n",
       "      <td>313513</td>\n",
       "      <td>313514</td>\n",
       "      <td>B000FNJ69S</td>\n",
       "      <td>A3S62P7QTO4P8V</td>\n",
       "      <td>Chad Susott \"Sparty DDS\"</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1283040000</td>\n",
       "      <td>Great with Sushi</td>\n",
       "      <td>I'm not a wasabi connoisseur by any means but ...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>235606</td>\n",
       "      <td>221591</td>\n",
       "      <td>221592</td>\n",
       "      <td>B004LM46EO</td>\n",
       "      <td>A3QEHZYAN9ZQKO</td>\n",
       "      <td>Amberhawke</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1326153600</td>\n",
       "      <td>Reunion Island is a fine coffee</td>\n",
       "      <td>Reunion Island SWP decaf is a nice, bold tasti...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>317360</td>\n",
       "      <td>225340</td>\n",
       "      <td>225341</td>\n",
       "      <td>B0008JEYQE</td>\n",
       "      <td>A2VFDVH1R6GLZB</td>\n",
       "      <td>Vanessa</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1178150400</td>\n",
       "      <td>Delicious European  Cookie</td>\n",
       "      <td>These cookies are really delicious!  You can't...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>91585</td>\n",
       "      <td>272255</td>\n",
       "      <td>272256</td>\n",
       "      <td>B0029O0HZS</td>\n",
       "      <td>AV6PAE2GAA9YM</td>\n",
       "      <td>N. Hogate \"Boomslang\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1300924800</td>\n",
       "      <td>A Definite Hit for my Cats!</td>\n",
       "      <td>I have four cats - ages 3 to 14, one of which ...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
       "0       325101        150237  150238  B001STX13U  A25KKXUQQ0OLWB   \n",
       "4        42280        313513  313514  B000FNJ69S  A3S62P7QTO4P8V   \n",
       "12      235606        221591  221592  B004LM46EO  A3QEHZYAN9ZQKO   \n",
       "21      317360        225340  225341  B0008JEYQE  A2VFDVH1R6GLZB   \n",
       "27       91585        272255  272256  B0029O0HZS   AV6PAE2GAA9YM   \n",
       "\n",
       "                           ProfileName  HelpfulnessNumerator  \\\n",
       "0   Lynn Ellingwood \"The ESOL Teacher\"                    10   \n",
       "4             Chad Susott \"Sparty DDS\"                     3   \n",
       "12                          Amberhawke                     5   \n",
       "21                             Vanessa                     2   \n",
       "27               N. Hogate \"Boomslang\"                     1   \n",
       "\n",
       "    HelpfulnessDenominator  Score        Time  \\\n",
       "0                       10      5  1282348800   \n",
       "4                        4      5  1283040000   \n",
       "12                       5      5  1326153600   \n",
       "21                       2      5  1178150400   \n",
       "27                       2      5  1300924800   \n",
       "\n",
       "                            Summary  \\\n",
       "0           My Cats' Favorite Food!   \n",
       "4                  Great with Sushi   \n",
       "12  Reunion Island is a fine coffee   \n",
       "21       Delicious European  Cookie   \n",
       "27      A Definite Hit for my Cats!   \n",
       "\n",
       "                                                 Text  helpScore  helpful  \\\n",
       "0   When this food came out, my cats went crazy th...       1.00     True   \n",
       "4   I'm not a wasabi connoisseur by any means but ...       0.75    False   \n",
       "12  Reunion Island SWP decaf is a nice, bold tasti...       1.00     True   \n",
       "21  These cookies are really delicious!  You can't...       1.00    False   \n",
       "27  I have four cats - ages 3 to 14, one of which ...       0.50    False   \n",
       "\n",
       "    svm_predictions  nbs_predicitons  nbs_predictions  \n",
       "0              True            False            False  \n",
       "4              True             True             True  \n",
       "12             True             True             True  \n",
       "21            False             True             True  \n",
       "27             True            False            False  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someoneSaysTrue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpfullness Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>nbs_predictions</th>\n",
       "      <th>svm_predictions</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>291348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>34171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>11665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   helpful  nbs_predictions  svm_predictions      Id\n",
       "0    False            False            False  291348\n",
       "1    False            False             True    5885\n",
       "2    False             True            False   34171\n",
       "3    False             True             True    6069\n",
       "4     True            False            False    7198\n",
       "5     True            False             True    2323\n",
       "6     True             True            False    5341\n",
       "7     True             True             True   11665"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpful_matrix = amazon.groupby(by=['helpful', 'nbs_predictions', 'svm_predictions'], as_index= False ).agg({'Id': \"count\"})\n",
    "helpful_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(helpful_matrix, values='Id', \n",
    "                       index=['nbs_predictions', 'svm_predictions'],\n",
    "                       columns=['helpful'], \n",
    "                       aggfunc= np.sum,\n",
    "                        margins = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbs_predictions</th>\n",
       "      <th>svm_predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>291348.00</td>\n",
       "      <td>7198.00</td>\n",
       "      <td>149273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>5885.00</td>\n",
       "      <td>2323.00</td>\n",
       "      <td>4104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>34171.00</td>\n",
       "      <td>5341.00</td>\n",
       "      <td>19756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>6069.00</td>\n",
       "      <td>11665.00</td>\n",
       "      <td>8867.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <td>84368.25</td>\n",
       "      <td>6631.75</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "helpful                              False      True       All\n",
       "nbs_predictions svm_predictions                               \n",
       "False           False            291348.00   7198.00  149273.0\n",
       "                True               5885.00   2323.00    4104.0\n",
       "True            False             34171.00   5341.00   19756.0\n",
       "                True               6069.00  11665.00    8867.0\n",
       "All                               84368.25   6631.75   45500.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore NBS Performance via Particular Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBS False Negatives -- Helpful reviews we missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at examples where nbs false negatives\n",
    "nbsFalseNegatives = someoneSaysTrue[someoneSaysTrue.helpful \n",
    "                & ~someoneSaysTrue.nbs_predictions ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "      <th>svm_predictions</th>\n",
       "      <th>nbs_predicitons</th>\n",
       "      <th>nbs_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325101</td>\n",
       "      <td>150237</td>\n",
       "      <td>150238</td>\n",
       "      <td>B001STX13U</td>\n",
       "      <td>A25KKXUQQ0OLWB</td>\n",
       "      <td>Lynn Ellingwood \"The ESOL Teacher\"</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1282348800</td>\n",
       "      <td>My Cats' Favorite Food!</td>\n",
       "      <td>When this food came out, my cats went crazy the first time I brought it home.  My older cats had liked the ground or classic cat food but these cats wouldn't have anything to do with it.  I've been buying this food for over a year and novelty hasn't worn off yet and even the cat across the street comes over for some.  They love it!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>359046</td>\n",
       "      <td>375241</td>\n",
       "      <td>375242</td>\n",
       "      <td>B00016LZR0</td>\n",
       "      <td>A18SNZN6Z16NCV</td>\n",
       "      <td>M. Taylor \"Myrna\"</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Great taste -- Very economical</td>\n",
       "      <td>Taste and aroma are great! A little goes a long way! Try it -- you'll like it!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>353294</td>\n",
       "      <td>417330</td>\n",
       "      <td>417331</td>\n",
       "      <td>B000HTDFCE</td>\n",
       "      <td>A2TNOL4SR0U08R</td>\n",
       "      <td>Accidental Tourist</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1168905600</td>\n",
       "      <td>Bakery on Main Gluten Free Granola</td>\n",
       "      <td>This is a tasty product, unlike some of the gluten-free foods that I have tried.  It is very crunchy with lots of fruit and nuts.  It has plenty of calories, but I use it as a topping for other, less-tasty cereals, e.g. bran flakes or some of the high-fiber cereals that remind me of twigs and leaves.  I will definitely be ordering more in the future.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>194094</td>\n",
       "      <td>80693</td>\n",
       "      <td>80694</td>\n",
       "      <td>B000MXHQR0</td>\n",
       "      <td>A2FZ46813P8MXQ</td>\n",
       "      <td>J. R. Cooke</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1251936000</td>\n",
       "      <td>Better than the box rice by far!</td>\n",
       "      <td>Whether or not it's right for you is up to you and your pediatrician to decide. We began adding it to our son's formula at 2 months because of health related issues. We currently use 1 scoop (scoop from Gerber formula can) of rice to 2 scoops of formula, and 4-5 oz of water. It mixes exceptionally well and is not \"goopy\" nor does it leave \"rice-sludge\" at the bottom of the bottle after feeding.&lt;br /&gt;We love this, and buy it over the box cereal every time now. Even our daycare has commented on how much they like this over the traditional flakes of rice cereal. The can fits better in the pantry than the box, and is much cleaner since it isn't leaking flakes from the corners and the fold down spout. The cans stack easily, and are the same size and shape as Gerber's formula cans.&lt;br /&gt;We initially purchased this from my wife's work, and when they ran out we switched back to box rice. It's cheaper from Amazon than it is at the local grocery stores. We're switching back to the can.&lt;br /&gt;&lt;br /&gt;Pros&lt;br /&gt;-It contains DHA to boost development.&lt;br /&gt;-Dissolves better; its more of a powder than the flakes you get in the box of Gerber rice cereal.&lt;br /&gt;-Because it dissolves better it is easier for the infant to drink, and easier to clean the bottle after feeding (large undissolved flakes don't clog the bottle).&lt;br /&gt;-Packaging is much cleaner than the boxes of rice cereal available from Gerber.&lt;br /&gt;&lt;br /&gt;Cons&lt;br /&gt;-It's not Vegan (if you care, I don't, but some other posters obviously do).&lt;br /&gt;-It does not come with a scoop. This is only a very minor inconvenience, as we, like the other poster, used the scoop from the can of Gerber formula that we use.&lt;br /&gt;&lt;br /&gt;I highly recommend this product.</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>62160</td>\n",
       "      <td>492727</td>\n",
       "      <td>492728</td>\n",
       "      <td>B000IW71BQ</td>\n",
       "      <td>A5P5FUZUK1NUL</td>\n",
       "      <td>critterlover</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>1184025600</td>\n",
       "      <td>My Cats LOVE These!</td>\n",
       "      <td>My 3 cats, including my youngest who doesn't like seafood (but loves to play in water!), LOVE these. I can't go to the cabinet without all 3 of them following me, meowing for these treats!&lt;br /&gt;&lt;br /&gt;And they're healthy because they're mostly air. So, my guys get this treat just about every evening. Buy them - Your cat(s) will love them, too. BTW, these were reviewed/tested by either Cat Fancy or Catnip magazine (where I first heard about them), and they got 5 stars because all of the test cats loved them.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>42429</td>\n",
       "      <td>127777</td>\n",
       "      <td>127778</td>\n",
       "      <td>B000LKYYT2</td>\n",
       "      <td>A1ZRKGV3H9EY55</td>\n",
       "      <td>Sunshine Girl</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1184889600</td>\n",
       "      <td>You won't even think your eating healthy....</td>\n",
       "      <td>I'm normally a very healthy yet picky eater.  These soy crisp are really delicious.  They look like little rice cakes, yet pack the taste of a potato chip.  I absolutely love snacking on them and with the serving size being 20 for at about 110 calories, that makes it even better.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>215758</td>\n",
       "      <td>468603</td>\n",
       "      <td>468604</td>\n",
       "      <td>B004HZFASG</td>\n",
       "      <td>ADOTOCNX9ZNTX</td>\n",
       "      <td>Jeremy Young</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1320019200</td>\n",
       "      <td>Love Shelled Pistachios!</td>\n",
       "      <td>I am excited about this, I have a handful every now and then.  I wish they had less salt but otherwise I am glad I don't have to shell the pistachios and deal with that mess.&lt;br /&gt;&lt;br /&gt;Also wish they used sea salt for less sodium as well.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>75543</td>\n",
       "      <td>424762</td>\n",
       "      <td>424763</td>\n",
       "      <td>B000EXWL8C</td>\n",
       "      <td>A3BN6WUWV6B4AQ</td>\n",
       "      <td>P. Smith</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1208304000</td>\n",
       "      <td>bonne maman is bon</td>\n",
       "      <td>This may be the best jam I have ever had.  Among other things (as near as I can tell) it has no artificial colors, preservatives, or corn syrup.  I think it does wonders for toast!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>333817</td>\n",
       "      <td>209691</td>\n",
       "      <td>209692</td>\n",
       "      <td>B000Q7535Y</td>\n",
       "      <td>A370FTMPRF0AIK</td>\n",
       "      <td>Aleta Jackson \"AJoy2Shop.com\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1234051200</td>\n",
       "      <td>Tasty Cookies</td>\n",
       "      <td>Very good product.  They are a tasty animal cookie with just the right sweetness.  This is an easy way to satisfy a \"sweet tooth\" without the guilt of eating something heavy.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>79975</td>\n",
       "      <td>138686</td>\n",
       "      <td>138687</td>\n",
       "      <td>B001IZBE2Y</td>\n",
       "      <td>A3OA0HGD9OTX4</td>\n",
       "      <td>Joni Ellsworth \"Rowdy Texan\"</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1271721600</td>\n",
       "      <td>Low fat, high fiber meal replacement bar</td>\n",
       "      <td>I eat a high protein meal replacement bar every day for breakfast, and I have lost several pounds.  The bar is high in protein, which does keep you fuller longer.  By lunchtime I am usually pretty hungry, but I can hold out until lunchtime without a problem.  They are a bit dry, so I always have a drink on hand while eating them.  The chocolate flavor is great, not that cheap tasting chocolate that usually comes with diet products.  The bar has a nice chew, but isn't overly chewy, nor does it stick to the teeth.  They have a good flavor - not the best bar I have ever eaten as far as taste goes, but better than tolerable for sure.  These bars are lower in fat content to some of the Slim Fast meal replacement bars, which is why I tried them in the first place.&lt;br /&gt;&lt;br /&gt;This high fiber bar will keep you feeling full for several hours, and replacing a meal a day with them does create results.  Following their diet plan of two meal replacement bars a day with three snack bars will more than likely increase weight loss from the few pounds I have lost eating one bar a day.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
       "0    325101      150237        150238  B001STX13U  A25KKXUQQ0OLWB   \n",
       "61   359046      375241        375242  B00016LZR0  A18SNZN6Z16NCV   \n",
       "121  353294      417330        417331  B000HTDFCE  A2TNOL4SR0U08R   \n",
       "195  194094      80693         80694   B000MXHQR0  A2FZ46813P8MXQ   \n",
       "238  62160       492727        492728  B000IW71BQ  A5P5FUZUK1NUL    \n",
       "281  42429       127777        127778  B000LKYYT2  A1ZRKGV3H9EY55   \n",
       "304  215758      468603        468604  B004HZFASG  ADOTOCNX9ZNTX    \n",
       "336  75543       424762        424763  B000EXWL8C  A3BN6WUWV6B4AQ   \n",
       "362  333817      209691        209692  B000Q7535Y  A370FTMPRF0AIK   \n",
       "407  79975       138686        138687  B001IZBE2Y  A3OA0HGD9OTX4    \n",
       "\n",
       "                            ProfileName  HelpfulnessNumerator  \\\n",
       "0    Lynn Ellingwood \"The ESOL Teacher\"  10                     \n",
       "61   M. Taylor \"Myrna\"                   6                      \n",
       "121  Accidental Tourist                  8                      \n",
       "195  J. R. Cooke                         9                      \n",
       "238  critterlover                        23                     \n",
       "281  Sunshine Girl                       5                      \n",
       "304  Jeremy Young                        9                      \n",
       "336  P. Smith                            4                      \n",
       "362  Aleta Jackson \"AJoy2Shop.com\"       4                      \n",
       "407  Joni Ellsworth \"Rowdy Texan\"        8                      \n",
       "\n",
       "     HelpfulnessDenominator  Score        Time  \\\n",
       "0    10                      5      1282348800   \n",
       "61   6                       5      1278201600   \n",
       "121  8                       5      1168905600   \n",
       "195  10                      5      1251936000   \n",
       "238  23                      5      1184025600   \n",
       "281  5                       5      1184889600   \n",
       "304  9                       4      1320019200   \n",
       "336  4                       5      1208304000   \n",
       "362  4                       5      1234051200   \n",
       "407  8                       3      1271721600   \n",
       "\n",
       "                                          Summary  \\\n",
       "0    My Cats' Favorite Food!                        \n",
       "61   Great taste -- Very economical                 \n",
       "121  Bakery on Main Gluten Free Granola             \n",
       "195  Better than the box rice by far!               \n",
       "238  My Cats LOVE These!                            \n",
       "281  You won't even think your eating healthy....   \n",
       "304  Love Shelled Pistachios!                       \n",
       "336  bonne maman is bon                             \n",
       "362  Tasty Cookies                                  \n",
       "407  Low fat, high fiber meal replacement bar       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Text  \\\n",
       "0    When this food came out, my cats went crazy the first time I brought it home.  My older cats had liked the ground or classic cat food but these cats wouldn't have anything to do with it.  I've been buying this food for over a year and novelty hasn't worn off yet and even the cat across the street comes over for some.  They love it!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "61   Taste and aroma are great! A little goes a long way! Try it -- you'll like it!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "121  This is a tasty product, unlike some of the gluten-free foods that I have tried.  It is very crunchy with lots of fruit and nuts.  It has plenty of calories, but I use it as a topping for other, less-tasty cereals, e.g. bran flakes or some of the high-fiber cereals that remind me of twigs and leaves.  I will definitely be ordering more in the future.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "195  Whether or not it's right for you is up to you and your pediatrician to decide. We began adding it to our son's formula at 2 months because of health related issues. We currently use 1 scoop (scoop from Gerber formula can) of rice to 2 scoops of formula, and 4-5 oz of water. It mixes exceptionally well and is not \"goopy\" nor does it leave \"rice-sludge\" at the bottom of the bottle after feeding.<br />We love this, and buy it over the box cereal every time now. Even our daycare has commented on how much they like this over the traditional flakes of rice cereal. The can fits better in the pantry than the box, and is much cleaner since it isn't leaking flakes from the corners and the fold down spout. The cans stack easily, and are the same size and shape as Gerber's formula cans.<br />We initially purchased this from my wife's work, and when they ran out we switched back to box rice. It's cheaper from Amazon than it is at the local grocery stores. We're switching back to the can.<br /><br />Pros<br />-It contains DHA to boost development.<br />-Dissolves better; its more of a powder than the flakes you get in the box of Gerber rice cereal.<br />-Because it dissolves better it is easier for the infant to drink, and easier to clean the bottle after feeding (large undissolved flakes don't clog the bottle).<br />-Packaging is much cleaner than the boxes of rice cereal available from Gerber.<br /><br />Cons<br />-It's not Vegan (if you care, I don't, but some other posters obviously do).<br />-It does not come with a scoop. This is only a very minor inconvenience, as we, like the other poster, used the scoop from the can of Gerber formula that we use.<br /><br />I highly recommend this product.   \n",
       "238  My 3 cats, including my youngest who doesn't like seafood (but loves to play in water!), LOVE these. I can't go to the cabinet without all 3 of them following me, meowing for these treats!<br /><br />And they're healthy because they're mostly air. So, my guys get this treat just about every evening. Buy them - Your cat(s) will love them, too. BTW, these were reviewed/tested by either Cat Fancy or Catnip magazine (where I first heard about them), and they got 5 stars because all of the test cats loved them.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "281  I'm normally a very healthy yet picky eater.  These soy crisp are really delicious.  They look like little rice cakes, yet pack the taste of a potato chip.  I absolutely love snacking on them and with the serving size being 20 for at about 110 calories, that makes it even better.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "304  I am excited about this, I have a handful every now and then.  I wish they had less salt but otherwise I am glad I don't have to shell the pistachios and deal with that mess.<br /><br />Also wish they used sea salt for less sodium as well.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "336  This may be the best jam I have ever had.  Among other things (as near as I can tell) it has no artificial colors, preservatives, or corn syrup.  I think it does wonders for toast!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "362  Very good product.  They are a tasty animal cookie with just the right sweetness.  This is an easy way to satisfy a \"sweet tooth\" without the guilt of eating something heavy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "407  I eat a high protein meal replacement bar every day for breakfast, and I have lost several pounds.  The bar is high in protein, which does keep you fuller longer.  By lunchtime I am usually pretty hungry, but I can hold out until lunchtime without a problem.  They are a bit dry, so I always have a drink on hand while eating them.  The chocolate flavor is great, not that cheap tasting chocolate that usually comes with diet products.  The bar has a nice chew, but isn't overly chewy, nor does it stick to the teeth.  They have a good flavor - not the best bar I have ever eaten as far as taste goes, but better than tolerable for sure.  These bars are lower in fat content to some of the Slim Fast meal replacement bars, which is why I tried them in the first place.<br /><br />This high fiber bar will keep you feeling full for several hours, and replacing a meal a day with them does create results.  Following their diet plan of two meal replacement bars a day with three snack bars will more than likely increase weight loss from the few pounds I have lost eating one bar a day.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "\n",
       "     helpScore  helpful  svm_predictions  nbs_predicitons  nbs_predictions  \n",
       "0    1.0        True     True             False            False            \n",
       "61   1.0        True     False            False            False            \n",
       "121  1.0        True     True             False            False            \n",
       "195  0.9        True     False            False            False            \n",
       "238  1.0        True     False            False            False            \n",
       "281  1.0        True     False            False            False            \n",
       "304  1.0        True     False            False            False            \n",
       "336  1.0        True     False            False            False            \n",
       "362  1.0        True     False            False            False            \n",
       "407  1.0        True     False            False            False            "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nbsFalseNegatives[:1]['Text']\n",
    "nbsFalseNegatives.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some ideas for what we missed:\n",
    "* features regarding subject lines + words used in them\n",
    "* including absolute time and not just relative to first review (though might lead to overfitting, depending on when the test set is taken from)\n",
    "* altering helpfulness score\n",
    "* adding in user id\n",
    "* adding in product id (might have an interaction with time)\n",
    "* key words that stick out: 'LOVE' 'loved' 'tested' 'reviewed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBS False Positives -- mistakely tagged reviews as helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbsFalsePositives = someoneSaysTrue[~someoneSaysTrue.helpful \n",
    "                & someoneSaysTrue.nbs_predictions ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "      <th>svm_predictions</th>\n",
       "      <th>nbs_predicitons</th>\n",
       "      <th>nbs_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42280</td>\n",
       "      <td>313513</td>\n",
       "      <td>313514</td>\n",
       "      <td>B000FNJ69S</td>\n",
       "      <td>A3S62P7QTO4P8V</td>\n",
       "      <td>Chad Susott \"Sparty DDS\"</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1283040000</td>\n",
       "      <td>Great with Sushi</td>\n",
       "      <td>I'm not a wasabi connoisseur by any means but I've recently become aquainted with the flavor and love it.  I like to mix this powder with soy sauce for sushi or with mayonaise for a little extra kick on a sandwich.  I've even sprinkled it on my popcorn, really good!</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>317360</td>\n",
       "      <td>225340</td>\n",
       "      <td>225341</td>\n",
       "      <td>B0008JEYQE</td>\n",
       "      <td>A2VFDVH1R6GLZB</td>\n",
       "      <td>Vanessa</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1178150400</td>\n",
       "      <td>Delicious European  Cookie</td>\n",
       "      <td>These cookies are really delicious!  You can't find them anywhere in the United States.  The outside of the cookie is crispy and light.  The inside filling is like a dry raspberry jam.  IT IS SOOOOOO good!  It is easy to eat the ENTIRE box in one sitting.  La Paille D'Or just came out with a blueberry filling, but you can only get those in Europe or in Tahiti!  Enjoy.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>188102</td>\n",
       "      <td>465571</td>\n",
       "      <td>465572</td>\n",
       "      <td>B000FFAK46</td>\n",
       "      <td>A1C26IVG56BKCZ</td>\n",
       "      <td>Free Spirit</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1296086400</td>\n",
       "      <td>Yum... Vinta baked with 8 grains &amp; seeds</td>\n",
       "      <td>I just bought a box from Trader Joe's for $2.19, wasn't sure if this tastes good but it turns out to be really good.&lt;br /&gt;&lt;br /&gt;After comparing the nutrition facts on several different brands of crackers, I settle with this one.&lt;br /&gt;For each 2 crackers:&lt;br /&gt;Calories=70-----Saturated Fat=1g-----Trans Fat=0g-----Cholesterol=0g-----Sodium=120mg&lt;br /&gt;Total Carb=8g-----Dietary Fiber=0g-----Sugar=1g-----Protein=1g&lt;br /&gt;&lt;br /&gt;Enjoy!!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>211710</td>\n",
       "      <td>38476</td>\n",
       "      <td>38477</td>\n",
       "      <td>B005MGDP86</td>\n",
       "      <td>A2RLAQA1QUITM2</td>\n",
       "      <td>marilyn91752</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1324425600</td>\n",
       "      <td>himalayan salt</td>\n",
       "      <td>I couldn't believe the wonderful flavor of this salt! And my doctor tells me that the trace minerals in it are actually good for me. I made a SOLE and use it every morning. Its great!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>114546</td>\n",
       "      <td>101139</td>\n",
       "      <td>101140</td>\n",
       "      <td>B0014B0HWK</td>\n",
       "      <td>A17AQQD8K5WB63</td>\n",
       "      <td>sss147</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1318464000</td>\n",
       "      <td>delicious</td>\n",
       "      <td>This tea is great.  I cook it in gallon batches and sweeten it with agave nectar and keep it in the fridge.  I guess it \"worked\" because my daughter was born after just 4 hours of labor and 20 minutes of pushing.  I'm still drinking it since I had just ordered another 3-pack of boxes of it the day before our baby was born.  My husband loves the tea too and he doesn't even have a uterus.</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>354759</td>\n",
       "      <td>567099</td>\n",
       "      <td>567100</td>\n",
       "      <td>B000G7V394</td>\n",
       "      <td>A1YYQYLDNSE6BO</td>\n",
       "      <td>Keith A. Moyer \"Pretzel man\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1256515200</td>\n",
       "      <td>From PA and live in KS</td>\n",
       "      <td>I am orginally from PA and Live in KS.  You just get get east coast pretzels like this out here.  No one buys them so store do not carry them.&lt;br /&gt;I love um.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>300017</td>\n",
       "      <td>433120</td>\n",
       "      <td>433121</td>\n",
       "      <td>B000SATIE6</td>\n",
       "      <td>A657G6UZGX5H1</td>\n",
       "      <td>Aaron702</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1264723200</td>\n",
       "      <td>Produces a deep, mellow flavor with hints of vanilla and black tea</td>\n",
       "      <td>If you are interested in a caffeine-free brew with a rich, full-bodied taste, you need to try Rooibos tea.  If you want the absolute best Rooibos for the price, you need to try Davidson's Tea in bulk.&lt;br /&gt;&lt;br /&gt;Rooibos is generally expensive, and many types available at the store are combined with other flavors (fruits and extracts).  Generally, all of these taste good, but each can hide the true quality of the Rooibos used.  The few pure Rooibos teas you find are closer to triple the price of normal 20 count boxes of teas.  These boxed Rooibos teas are actually quite good, one or two are even better than this Davidson's Tea, but expensive--you might get 1.5 ounces for the price.  Amazingly, Davidson's is able to give you 16 ounces of Rooibos for a couple dollars more.&lt;br /&gt;&lt;br /&gt;We like our Rooibos strong and we would go through it very fast with Rooibos by-the-bag, so we seldom get the pure Rooibos.  That is, until now with this bulk version.&lt;br /&gt;&lt;br /&gt;Coupled with a good method of infusing (I highly suggest the SwissGold TF 500--it is non-reactive with the tea and it is sufficiently sized and made for extended use), you will make great brews.  Rooibos can give you two great brews, and a third brew that is, at best, mediocre (make this a hotter, longer brew), using four teaspoons in the TF 500 mentioned above.  This keeps me going until evening, when I share another set of strong brews with my wife.  As you may tell, I use a very large mug.  :-)&lt;br /&gt;&lt;br /&gt;The bag is plastic-lined paper, and has strong ziplock-type top.  You can probably get by leaving the tea in the bag for some weeks, but if you need to keep it for longer, you should buy vacuum containers.&lt;br /&gt;&lt;br /&gt;We are elated with this so much, that we've ordered four other Davidson's bulk teas.  Expect reviews on these soon.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>33220</td>\n",
       "      <td>492321</td>\n",
       "      <td>492322</td>\n",
       "      <td>B001KUWEL2</td>\n",
       "      <td>A2KC8TUNAIUUSK</td>\n",
       "      <td>Zachary Palmer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1271635200</td>\n",
       "      <td>Steel cut oats are the way to go, for the sake of texture.</td>\n",
       "      <td>While you may not be astounded by the difference in flavor from standard rolled oats (the standard these days on the shelves I see), the difference in texture is quite nice. That subtly chewy texture from oats that aren't over-cooked is nice to have, and makes quite a difference. As another reviewer stated, add some fruit or season it, don't expect a cereal grain to be appealing on its own. This is a healthy cereal with decent fiber content, some of which is soluble (helps with cholesterol) and some insoluble (colon health). And as amazon purchases go, the price alone isn't horrible.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>256952</td>\n",
       "      <td>185096</td>\n",
       "      <td>185097</td>\n",
       "      <td>B000EEWZF0</td>\n",
       "      <td>A1E27F043ABYGD</td>\n",
       "      <td>James J. Bos \"jbosman\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1327881600</td>\n",
       "      <td>Best Sardines on the Market</td>\n",
       "      <td>I like sardines and have tried many different brands.  These are, hands down, the best Sardines on the market.  Very tasty, no bones in a light olive oil.  Highly recommended.  Good source of Omega 3's as well.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>131580</td>\n",
       "      <td>347740</td>\n",
       "      <td>347741</td>\n",
       "      <td>B001E5E3MQ</td>\n",
       "      <td>AKOQ0ZTRDGQDO</td>\n",
       "      <td>Cheryl A. Benefiel \"cbaby 56\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1323216000</td>\n",
       "      <td>What a great deal!</td>\n",
       "      <td>I have been on the HCG Protocol Diet. I had bought the SweetLeaf Liquid Stevia Lemon Drop on their official website. It was more for 1 bottle on their website than for 2 bottles on Amazon. I will definitely buy more from Amazon. They also have other flavors if you don't like lemon. What a great deal!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
       "4    42280       313513        313514  B000FNJ69S  A3S62P7QTO4P8V   \n",
       "21   317360      225340        225341  B0008JEYQE  A2VFDVH1R6GLZB   \n",
       "35   188102      465571        465572  B000FFAK46  A1C26IVG56BKCZ   \n",
       "46   211710      38476         38477   B005MGDP86  A2RLAQA1QUITM2   \n",
       "72   114546      101139        101140  B0014B0HWK  A17AQQD8K5WB63   \n",
       "77   354759      567099        567100  B000G7V394  A1YYQYLDNSE6BO   \n",
       "80   300017      433120        433121  B000SATIE6  A657G6UZGX5H1    \n",
       "83   33220       492321        492322  B001KUWEL2  A2KC8TUNAIUUSK   \n",
       "115  256952      185096        185097  B000EEWZF0  A1E27F043ABYGD   \n",
       "122  131580      347740        347741  B001E5E3MQ  AKOQ0ZTRDGQDO    \n",
       "\n",
       "                       ProfileName  HelpfulnessNumerator  \\\n",
       "4    Chad Susott \"Sparty DDS\"       3                      \n",
       "21   Vanessa                        2                      \n",
       "35   Free Spirit                    1                      \n",
       "46   marilyn91752                   0                      \n",
       "72   sss147                         5                      \n",
       "77   Keith A. Moyer \"Pretzel man\"   0                      \n",
       "80   Aaron702                       2                      \n",
       "83   Zachary Palmer                 0                      \n",
       "115  James J. Bos \"jbosman\"         0                      \n",
       "122  Cheryl A. Benefiel \"cbaby 56\"  1                      \n",
       "\n",
       "     HelpfulnessDenominator  Score        Time  \\\n",
       "4    4                       5      1283040000   \n",
       "21   2                       5      1178150400   \n",
       "35   1                       5      1296086400   \n",
       "46   0                       5      1324425600   \n",
       "72   6                       5      1318464000   \n",
       "77   0                       5      1256515200   \n",
       "80   2                       5      1264723200   \n",
       "83   0                       4      1271635200   \n",
       "115  0                       5      1327881600   \n",
       "122  1                       5      1323216000   \n",
       "\n",
       "                                                                Summary  \\\n",
       "4    Great with Sushi                                                     \n",
       "21   Delicious European  Cookie                                           \n",
       "35   Yum... Vinta baked with 8 grains & seeds                             \n",
       "46   himalayan salt                                                       \n",
       "72   delicious                                                            \n",
       "77   From PA and live in KS                                               \n",
       "80   Produces a deep, mellow flavor with hints of vanilla and black tea   \n",
       "83   Steel cut oats are the way to go, for the sake of texture.           \n",
       "115  Best Sardines on the Market                                          \n",
       "122  What a great deal!                                                   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Text  \\\n",
       "4    I'm not a wasabi connoisseur by any means but I've recently become aquainted with the flavor and love it.  I like to mix this powder with soy sauce for sushi or with mayonaise for a little extra kick on a sandwich.  I've even sprinkled it on my popcorn, really good!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "21   These cookies are really delicious!  You can't find them anywhere in the United States.  The outside of the cookie is crispy and light.  The inside filling is like a dry raspberry jam.  IT IS SOOOOOO good!  It is easy to eat the ENTIRE box in one sitting.  La Paille D'Or just came out with a blueberry filling, but you can only get those in Europe or in Tahiti!  Enjoy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "35   I just bought a box from Trader Joe's for $2.19, wasn't sure if this tastes good but it turns out to be really good.<br /><br />After comparing the nutrition facts on several different brands of crackers, I settle with this one.<br />For each 2 crackers:<br />Calories=70-----Saturated Fat=1g-----Trans Fat=0g-----Cholesterol=0g-----Sodium=120mg<br />Total Carb=8g-----Dietary Fiber=0g-----Sugar=1g-----Protein=1g<br /><br />Enjoy!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "46   I couldn't believe the wonderful flavor of this salt! And my doctor tells me that the trace minerals in it are actually good for me. I made a SOLE and use it every morning. Its great!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "72   This tea is great.  I cook it in gallon batches and sweeten it with agave nectar and keep it in the fridge.  I guess it \"worked\" because my daughter was born after just 4 hours of labor and 20 minutes of pushing.  I'm still drinking it since I had just ordered another 3-pack of boxes of it the day before our baby was born.  My husband loves the tea too and he doesn't even have a uterus.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "77   I am orginally from PA and Live in KS.  You just get get east coast pretzels like this out here.  No one buys them so store do not carry them.<br />I love um.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "80   If you are interested in a caffeine-free brew with a rich, full-bodied taste, you need to try Rooibos tea.  If you want the absolute best Rooibos for the price, you need to try Davidson's Tea in bulk.<br /><br />Rooibos is generally expensive, and many types available at the store are combined with other flavors (fruits and extracts).  Generally, all of these taste good, but each can hide the true quality of the Rooibos used.  The few pure Rooibos teas you find are closer to triple the price of normal 20 count boxes of teas.  These boxed Rooibos teas are actually quite good, one or two are even better than this Davidson's Tea, but expensive--you might get 1.5 ounces for the price.  Amazingly, Davidson's is able to give you 16 ounces of Rooibos for a couple dollars more.<br /><br />We like our Rooibos strong and we would go through it very fast with Rooibos by-the-bag, so we seldom get the pure Rooibos.  That is, until now with this bulk version.<br /><br />Coupled with a good method of infusing (I highly suggest the SwissGold TF 500--it is non-reactive with the tea and it is sufficiently sized and made for extended use), you will make great brews.  Rooibos can give you two great brews, and a third brew that is, at best, mediocre (make this a hotter, longer brew), using four teaspoons in the TF 500 mentioned above.  This keeps me going until evening, when I share another set of strong brews with my wife.  As you may tell, I use a very large mug.  :-)<br /><br />The bag is plastic-lined paper, and has strong ziplock-type top.  You can probably get by leaving the tea in the bag for some weeks, but if you need to keep it for longer, you should buy vacuum containers.<br /><br />We are elated with this so much, that we've ordered four other Davidson's bulk teas.  Expect reviews on these soon.   \n",
       "83   While you may not be astounded by the difference in flavor from standard rolled oats (the standard these days on the shelves I see), the difference in texture is quite nice. That subtly chewy texture from oats that aren't over-cooked is nice to have, and makes quite a difference. As another reviewer stated, add some fruit or season it, don't expect a cereal grain to be appealing on its own. This is a healthy cereal with decent fiber content, some of which is soluble (helps with cholesterol) and some insoluble (colon health). And as amazon purchases go, the price alone isn't horrible.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "115  I like sardines and have tried many different brands.  These are, hands down, the best Sardines on the market.  Very tasty, no bones in a light olive oil.  Highly recommended.  Good source of Omega 3's as well.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "122  I have been on the HCG Protocol Diet. I had bought the SweetLeaf Liquid Stevia Lemon Drop on their official website. It was more for 1 bottle on their website than for 2 bottles on Amazon. I will definitely buy more from Amazon. They also have other flavors if you don't like lemon. What a great deal!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "     helpScore  helpful  svm_predictions  nbs_predicitons  nbs_predictions  \n",
       "4    0.750000   False    True             True             True             \n",
       "21   1.000000   False    False            True             True             \n",
       "35   1.000000   False    False            True             True             \n",
       "46  NaN         False    False            True             True             \n",
       "72   0.833333   False    False            True             True             \n",
       "77  NaN         False    False            True             True             \n",
       "80   1.000000   False    False            True             True             \n",
       "83  NaN         False    False            True             True             \n",
       "115 NaN         False    False            True             True             \n",
       "122  1.000000   False    False            True             True             "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbsFalsePositives.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67206759443339958"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many of my false positives have to do with low denominator scores?\n",
    "# suggesting that there just aren't enough people who have voted yet\n",
    "\n",
    "(nbsFalsePositives.HelpfulnessDenominator <= 1).sum() / (nbsFalsePositives.shape[0])\n",
    "\n",
    "# 67% of my false positives were based on too little reviews -- \n",
    "#is there a predictor I can find for that that wouldn't overfit the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
